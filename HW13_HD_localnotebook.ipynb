{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASCI W261: Machine Learning at Scale \n",
    "** W261-4 Spring 2016   \n",
    "Assignment 13   \n",
    "April 24, 2016**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name **HUSSEIN DANISH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labVersion = 'MIDS_MLS_HW_13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.6.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.11 (default, Dec  6 2015 18:08:32)\n",
      "SparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "spark_home = os.environ['SPARK_HOME'] = '/home/hdanish/Downloads/spark-1.6.1-bin-hadoop2.6/'\n",
    "\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME enviroment variable is not set')\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "execfile(os.path.join(spark_home,'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** HW 13.1: Spark implementation of basic PageRank **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a basic Spark implementation of the iterative PageRank algorithm that takes sparse adjacency lists as input.\n",
    "\n",
    "Make sure that your implementation utilizes teleportation (1-damping/the number of nodes in the network), and further, distributes the mass of dangling nodes with each iteration so that the output of each iteration is correctly normalized (sums to 1). [NOTE: The PageRank algorithm assumes that a random surfer (walker), starting from a random web page, chooses the next page to which it will move by clicking at random, with probability d, one of the hyperlinks in the current page. This probability is represented by a so-called ‘damping factor’ d, where d ∈ (0, 1). Otherwise, with probability (1 − d), the surfer jumps to any web page in the network. If a page is a dangling end, meaning it has no outgoing hyperlinks, the random surfer selects an arbitrary web page from a uniform\n",
    "distribution and “teleports” to that page]\n",
    "\n",
    "In your Spark solution, please use broadcast variables and caching to make sure your code is as efficient as possible.\n",
    "\n",
    "As you build your code, use the test data\n",
    "\n",
    "s3://ucb-mids-mls-networks/PageRank-test.txt\n",
    "\n",
    "Or under the Data Subfolder for HW7 on Dropbox with the same file name. \n",
    "\n",
    "(On Dropbox https://www.dropbox.com/sh/2c0k5adwz36lkcw/AAAAKsjQfF9uHfv-X9mCqr9wa?dl=0)\n",
    "\n",
    "with teleportation parameter set to 0.15 (1-d, where d, the damping factor is set to 0.85), and crosscheck\n",
    "your work with the true result, displayed in the first image\n",
    "in the Wikipedia article:\n",
    "\n",
    "https://en.wikipedia.org/wiki/PageRank\n",
    "\n",
    "and here for reference are the corresponding PageRank probabilities:\n",
    "\n",
    "A,0.033\n",
    "B,0.384\n",
    "C,0.343\n",
    "D,0.039\n",
    "E,0.081\n",
    "F,0.039\n",
    "G,0.016\n",
    "H,0.016\n",
    "I,0.016\n",
    "J,0.016\n",
    "K,0.016\n",
    "\n",
    "Run this experiment locally first. Report the local configuration that you used and how long in minutes and seconds it takes to complete your job.\n",
    "\n",
    "Repeat this experiment on AWS. Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete your job. (in your notebook, cat the cluster config file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filip Krunic implementation\n",
    "# Parse \n",
    "def parseRaw(line):    \n",
    "    \"\"\" This function parses the graph elements from the dictionary.\"\"\"\n",
    "    \n",
    "    # Separate\n",
    "    array = line.split('\\t')\n",
    "    node, neighbors = array \n",
    "    neighbors = eval(neighbors)\n",
    "    \n",
    "    # Emit\n",
    "    for k in neighbors.keys(): \n",
    "        yield (node, [k])\n",
    "        yield (k, [])\n",
    "        \n",
    "\n",
    "# Calculate PageRank \n",
    "def emitPR(line):    \n",
    "    # Unpack\n",
    "    node, prTuple = line\n",
    "    prList, rank = prTuple\n",
    "    \n",
    "    # Emit \n",
    "    for neighbor in prList: \n",
    "        yield (neighbor, rank / len(prList))\n",
    "        \n",
    "        # Danglers \n",
    "        yield (node, 0)\n",
    "        \n",
    "        \n",
    "# Compute PR with Teleport \n",
    "def dampenedPR(line, danglerLoss, totalDanglers, totalNodes, d=0.85):        \n",
    "    # Unpack\n",
    "    node, PR = line \n",
    "    \n",
    "    # Update \n",
    "    PR *= d\n",
    "    PR += (1 - d + d * danglerLoss / totalDanglers ) / totalNodes\n",
    "    \n",
    "    # Emit \n",
    "    return (node, PR)    \n",
    "        \n",
    "        \n",
    "######## INITIALIZE #########\n",
    "def initPageRank(infile, outfile, n=10):\n",
    "    # Load \n",
    "    graphData = sc.textFile(infile).flatMap(lambda x: parseRaw(x)).reduceByKey(lambda a, b: a + b).cache()\n",
    "    rank = graphData.map(lambda x: (x[0], 1))\n",
    "\n",
    "    # Dangling \n",
    "    danglers = graphData.filter(lambda x: not bool(x[1]))\n",
    "    totalDanglers = danglers.count()\n",
    "\n",
    "    # Diag\n",
    "    totalNodes = graphData.count()\n",
    "\n",
    "    # PageRank\n",
    "    for i in range(n):\n",
    "        # Neighbor contributions \n",
    "        PR = graphData.join(rank).flatMap(lambda x: emitPR(x)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "        # Dangling PR\n",
    "        danglerPR = PR.join(danglers).map(lambda x: (x[0], x[1][0]))\n",
    "        danglerLoss = danglerPR.map(lambda x: x[1]).sum()\n",
    "\n",
    "        # Dampening\n",
    "        dPR = PR.map(lambda x: dampenedPR(x, danglerLoss, totalDanglers, totalNodes))\n",
    "\n",
    "        # Normalize \n",
    "        totalWeight = dPR.map(lambda x: x[1]).sum()\n",
    "        nPR = dPR.map(lambda x: (x[0], x[1] / totalWeight))\n",
    "\n",
    "        # Cycle \n",
    "        rank = nPR\n",
    "\n",
    "    # Results \n",
    "    rank.saveAsTextFile(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "10 iterations took 47.5687220097 seconds\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "initPageRank('PageRank-test.txt', 'pr10-2')\n",
    "endTime = time.time()\n",
    "print '\\n'\n",
    "print '10 iterations took ' + str(endTime - startTime) + \" seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'B', 0.3910656743458547)\r\n",
      "(u'G', 0.015252405206487117)\r\n",
      "(u'J', 0.015252405206487117)\r\n",
      "('A', 0.03138768904445686)\r\n",
      "(u'I', 0.015252405206487117)\r\n",
      "(u'D', 0.03744461211710654)\r\n",
      "('C', 0.3491026787812407)\r\n",
      "(u'K', 0.015252405206487117)\r\n",
      "('F', 0.03744461211710654)\r\n",
      "('E', 0.07729270756179903)\r\n",
      "(u'H', 0.015252405206487117)\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./pr10-2/part-* > ./pr10-2.txt\n",
    "!head -n 11 ./pr10-2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###HW 13.3: Spark GraphX versus your implementation of PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Spark  GraphX PageRank implementation on the Wikipedia dataset for 10 iterations,\n",
    "and display the top 100 ranked nodes (with alpha = 0.85).\n",
    "\n",
    "Run your PageRank implementation on the Wikipedia dataset for 50 iterations,\n",
    "and display the top 100 ranked nodes (with teleportation factor of 0.15). \n",
    "Have the top 100 ranked pages changed? Comment on your findings. Plot both 100 curves.\n",
    "\n",
    "Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete this job.\n",
    "\n",
    "Put the runtime results of HW13.2 and HW13.3 in a tabular format (with rows corresponding to implemention and columns corresponding to experiment setup (10 iterations, 50 iterations)). Discuss the run times and explaing the differences. \n",
    "\n",
    "Plot the pagerank values for the top 100 pages resulting from the 50 iterations run (using GraphX). Then plot the pagerank values for the same 100 pages that resulted from the 50 iterations run of your homegrown pagerank implemnentation.  Comment on your findings.  Have the top 100 ranked pages changed? Have the pagerank values changed? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First trying this out on the toy set\n",
    "# We want to parse the input to have a file with format \"NODE NEIGHBOUR\" on each line\n",
    "def graphxParse(line):\n",
    "    node, links = line.split('\\t')\n",
    "    for link in eval(links).keys():\n",
    "        yield node + ' ' + link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2\n",
      "5 4\n",
      "5 6\n"
     ]
    }
   ],
   "source": [
    "# Try out this function\n",
    "for e in graphxParse(\"5\t{'4': 1, '2': 1, '6': 1}\"):\n",
    "    print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we want to create our input file\n",
    "def graphxInit(infile, outfile):\n",
    "    sc.textFile(infile).flatMap(lambda x: graphxParse(x)).saveAsTextFile(outfile)\n",
    "    \n",
    "graphxInit('PageRank-test_indexed.txt', 'toygraph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\r\n",
      "3 2\r\n",
      "4 1\r\n",
      "4 2\r\n",
      "5 2\r\n",
      "5 4\r\n",
      "5 6\r\n",
      "6 2\r\n",
      "6 5\r\n",
      "7 2\r\n",
      "7 5\r\n",
      "8 2\r\n",
      "8 5\r\n",
      "9 2\r\n",
      "9 5\r\n",
      "10 5\r\n",
      "11 5\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./toygraph/part-* > ./toygraph.txt\n",
    "!cat ./toygraph.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pagerank.scala\n"
     ]
    }
   ],
   "source": [
    "%%writefile pagerank.scala\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.graphx._\n",
    "\n",
    "object HWPageRank {\n",
    "    def main(args: Array[String]) {\n",
    "        val conf = new SparkConf().setAppName(\"pagerank\")\n",
    "        val sc = new SparkContext(conf)\n",
    "        \n",
    "        val graph = GraphLoader.edgeListFile(sc, \"/home/hdanish/Documents/UCB/W261/Week13/toygraph.txt\")\n",
    "\n",
    "        val ranks = graph.staticPageRank(10).vertices\n",
    "        \n",
    "        val top100 = ranks.sortBy(_._2, false).take(100)\n",
    "        sc.parallelize(top100).saveAsTextFile(\"pr10g-1\")        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing build.sbt\n"
     ]
    }
   ],
   "source": [
    "%%writefile build.sbt\n",
    "name := \"pagerank\"\n",
    "version := \"1.0\"\n",
    "scalaVersion := \"2.10.5\"\n",
    "libraryDependencies ++= Seq(\"org.apache.spark\" %% \"spark-core\" % \"1.6.1\", \"org.apache.spark\" %% \"spark-graphx\" % \"1.6.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory layout should look like this\n",
    "\n",
    "$ find .\n",
    "\n",
    ".\n",
    "\n",
    "./build.sbt\n",
    "\n",
    "./src\n",
    "\n",
    "./src/main\n",
    "\n",
    "./src/main/scala\n",
    "\n",
    "./src/main/scala/pagerank.scala\n",
    "\n",
    "**So need to create subdirectories src, src/main, src/main/scala and then put the scala file in the last subdirectory**\n",
    "\n",
    "Then we can run the next steps which is \"sbt package\" to compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m[\u001b[0minfo\u001b[0m] \u001b[0mSet current project to pagerank (in build file:/home/hdanish/Documents/UCB/W261/Week13/)\u001b[0m\n",
      "\u001b[0m[\u001b[32msuccess\u001b[0m] \u001b[0mTotal time: 3 s, completed 28-Apr-2016 8:28:04 PM\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sbt package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "16/04/28 19:56:13 INFO SparkContext: Running Spark version 1.6.1\n",
      "16/04/28 19:56:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "16/04/28 19:56:14 WARN Utils: Your hostname, hdanish-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface eth0)\n",
      "16/04/28 19:56:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "16/04/28 19:56:14 INFO SecurityManager: Changing view acls to: hdanish\n",
      "16/04/28 19:56:14 INFO SecurityManager: Changing modify acls to: hdanish\n",
      "16/04/28 19:56:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdanish); users with modify permissions: Set(hdanish)\n",
      "16/04/28 19:56:15 INFO Utils: Successfully started service 'sparkDriver' on port 56027.\n",
      "16/04/28 19:56:16 INFO Slf4jLogger: Slf4jLogger started\n",
      "16/04/28 19:56:17 INFO Remoting: Starting remoting\n",
      "16/04/28 19:56:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.0.2.15:47027]\n",
      "16/04/28 19:56:17 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 47027.\n",
      "16/04/28 19:56:17 INFO SparkEnv: Registering MapOutputTracker\n",
      "16/04/28 19:56:17 INFO SparkEnv: Registering BlockManagerMaster\n",
      "16/04/28 19:56:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8e0b6bff-87c3-4d4c-a58f-2fe0d4cd3ed7\n",
      "16/04/28 19:56:17 INFO MemoryStore: MemoryStore started with capacity 517.4 MB\n",
      "16/04/28 19:56:18 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "16/04/28 19:56:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "16/04/28 19:56:38 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "16/04/28 19:56:38 INFO SparkUI: Started SparkUI at http://10.0.2.15:4041\n",
      "16/04/28 19:56:39 INFO HttpFileServer: HTTP File server directory is /tmp/spark-1a966d7a-0651-418c-b009-0762aa5e49d2/httpd-9cb04eaa-6892-4f76-afd2-e25c04a55a54\n",
      "16/04/28 19:56:39 INFO HttpServer: Starting HTTP Server\n",
      "16/04/28 19:56:39 INFO Utils: Successfully started service 'HTTP file server' on port 45203.\n",
      "16/04/28 19:56:39 INFO SparkContext: Added JAR file:/home/hdanish/Documents/UCB/W261/Week13/target/scala-2.10/pagerank_2.10-1.0.jar at http://10.0.2.15:45203/jars/pagerank_2.10-1.0.jar with timestamp 1461887799258\n",
      "16/04/28 19:56:39 INFO Executor: Starting executor ID driver on host localhost\n",
      "16/04/28 19:56:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40918.\n",
      "16/04/28 19:56:40 INFO NettyBlockTransferService: Server created on 40918\n",
      "16/04/28 19:56:40 INFO BlockManagerMaster: Trying to register BlockManager\n",
      "16/04/28 19:56:40 INFO BlockManagerMasterEndpoint: Registering block manager localhost:40918 with 517.4 MB RAM, BlockManagerId(driver, localhost, 40918)\n",
      "16/04/28 19:56:40 INFO BlockManagerMaster: Registered BlockManager\n",
      "16/04/28 19:56:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 153.6 KB, free 153.6 KB)\n",
      "16/04/28 19:56:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.9 KB, free 167.5 KB)\n",
      "16/04/28 19:56:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40918 (size: 13.9 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:41 INFO SparkContext: Created broadcast 0 from textFile at GraphLoader.scala:72\n",
      "16/04/28 19:56:42 INFO FileInputFormat: Total input paths to process : 1\n",
      "16/04/28 19:56:42 INFO SparkContext: Starting job: count at GraphLoader.scala:93\n",
      "16/04/28 19:56:42 INFO DAGScheduler: Got job 0 (count at GraphLoader.scala:93) with 2 output partitions\n",
      "16/04/28 19:56:42 INFO DAGScheduler: Final stage: ResultStage 0 (count at GraphLoader.scala:93)\n",
      "16/04/28 19:56:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "16/04/28 19:56:42 INFO DAGScheduler: Missing parents: List()\n",
      "16/04/28 19:56:42 INFO DAGScheduler: Submitting ResultStage 0 (GraphLoader.edgeListFile - edges (/home/hdanish/Documents/UCB/W261/Week13/toygraph.txt) MapPartitionsRDD[2] at mapPartitionsWithIndex at GraphLoader.scala:74), which has no missing parents\n",
      "16/04/28 19:56:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 170.7 KB)\n",
      "16/04/28 19:56:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1967.0 B, free 172.7 KB)\n",
      "16/04/28 19:56:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:40918 (size: 1967.0 B, free: 517.4 MB)\n",
      "16/04/28 19:56:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (GraphLoader.edgeListFile - edges (/home/hdanish/Documents/UCB/W261/Week13/toygraph.txt) MapPartitionsRDD[2] at mapPartitionsWithIndex at GraphLoader.scala:74)\n",
      "16/04/28 19:56:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks\n",
      "16/04/28 19:56:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2218 bytes)\n",
      "16/04/28 19:56:42 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2218 bytes)\n",
      "16/04/28 19:56:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "16/04/28 19:56:42 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)\n",
      "16/04/28 19:56:42 INFO Executor: Fetching http://10.0.2.15:45203/jars/pagerank_2.10-1.0.jar with timestamp 1461887799258\n",
      "16/04/28 19:56:43 INFO Utils: Fetching http://10.0.2.15:45203/jars/pagerank_2.10-1.0.jar to /tmp/spark-1a966d7a-0651-418c-b009-0762aa5e49d2/userFiles-a5ece9c6-21e6-4e88-bc7d-4fc37f1e4792/fetchFileTemp3407222993300348726.tmp\n",
      "16/04/28 19:56:43 INFO Executor: Adding file:/tmp/spark-1a966d7a-0651-418c-b009-0762aa5e49d2/userFiles-a5ece9c6-21e6-4e88-bc7d-4fc37f1e4792/pagerank_2.10-1.0.jar to class loader\n",
      "16/04/28 19:56:43 INFO CacheManager: Partition rdd_2_1 not found, computing it\n",
      "16/04/28 19:56:43 INFO CacheManager: Partition rdd_2_0 not found, computing it\n",
      "16/04/28 19:56:43 INFO HadoopRDD: Input split: file:/home/hdanish/Documents/UCB/W261/Week13/toygraph.txt:0+35\n",
      "16/04/28 19:56:43 INFO HadoopRDD: Input split: file:/home/hdanish/Documents/UCB/W261/Week13/toygraph.txt:35+35\n",
      "16/04/28 19:56:43 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "16/04/28 19:56:43 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "16/04/28 19:56:43 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "16/04/28 19:56:43 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "16/04/28 19:56:43 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "16/04/28 19:56:43 INFO MemoryStore: Block rdd_2_0 stored as values in memory (estimated size 2.6 KB, free 175.2 KB)\n",
      "16/04/28 19:56:43 INFO MemoryStore: Block rdd_2_1 stored as values in memory (estimated size 2.5 KB, free 177.8 KB)\n",
      "16/04/28 19:56:43 INFO BlockManagerInfo: Added rdd_2_1 in memory on localhost:40918 (size: 2.5 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:43 INFO BlockManagerInfo: Added rdd_2_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2662 bytes result sent to driver\n",
      "16/04/28 19:56:43 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2662 bytes result sent to driver\n",
      "16/04/28 19:56:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1240 ms on localhost (1/2)\n",
      "16/04/28 19:56:43 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1223 ms on localhost (2/2)\n",
      "16/04/28 19:56:43 INFO DAGScheduler: ResultStage 0 (count at GraphLoader.scala:93) finished in 1.337 s\n",
      "16/04/28 19:56:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:44 INFO DAGScheduler: Job 0 finished: count at GraphLoader.scala:93, took 1.954624 s\n",
      "16/04/28 19:56:44 INFO GraphLoader: It took 3542 ms to load the edges\n",
      "16/04/28 19:56:44 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:150\n",
      "16/04/28 19:56:44 INFO DAGScheduler: Registering RDD 11 (mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:44 INFO DAGScheduler: Registering RDD 5 (mapPartitions at VertexRDD.scala:358)\n",
      "16/04/28 19:56:44 INFO DAGScheduler: Registering RDD 19 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 85 bytes\n",
      "16/04/28 19:56:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 85 bytes\n",
      "16/04/28 19:56:44 INFO DAGScheduler: Registering RDD 29 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:44 INFO DAGScheduler: Registering RDD 33 (mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:44 INFO DAGScheduler: Registering RDD 41 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:44 INFO DAGScheduler: Got job 1 (foreachPartition at PageRank.scala:150) with 2 output partitions\n",
      "16/04/28 19:56:44 INFO DAGScheduler: Final stage: ResultStage 9 (foreachPartition at PageRank.scala:150)\n",
      "16/04/28 19:56:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6, ShuffleMapStage 3, ShuffleMapStage 8)\n",
      "16/04/28 19:56:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6, ShuffleMapStage 3, ShuffleMapStage 8)\n",
      "16/04/28 19:56:45 INFO DAGScheduler: Submitting ShuffleMapStage 4 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[5] at mapPartitions at VertexRDD.scala:358), which has no missing parents\n",
      "16/04/28 19:56:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.1 KB, free 181.8 KB)\n",
      "16/04/28 19:56:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 184.2 KB)\n",
      "16/04/28 19:56:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:40918 (size: 2.3 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 4 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[5] at mapPartitions at VertexRDD.scala:358)\n",
      "16/04/28 19:56:45 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks\n",
      "16/04/28 19:56:45 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2207 bytes)\n",
      "16/04/28 19:56:45 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2207 bytes)\n",
      "16/04/28 19:56:45 INFO DAGScheduler: Submitting ShuffleMapStage 5 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[11] at mapPartitions at GraphImpl.scala:235), which has no missing parents\n",
      "16/04/28 19:56:45 INFO Executor: Running task 0.0 in stage 4.0 (TID 2)\n",
      "16/04/28 19:56:45 INFO Executor: Running task 1.0 in stage 4.0 (TID 3)\n",
      "16/04/28 19:56:45 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.6 KB, free 188.7 KB)\n",
      "16/04/28 19:56:45 INFO BlockManager: Found block rdd_2_0 locally\n",
      "16/04/28 19:56:45 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.6 KB, free 191.4 KB)\n",
      "16/04/28 19:56:45 INFO BlockManager: Found block rdd_2_1 locally\n",
      "16/04/28 19:56:45 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:40918 (size: 2.6 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:45 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[11] at mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks\n",
      "16/04/28 19:56:45 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2207 bytes)\n",
      "16/04/28 19:56:45 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2207 bytes)\n",
      "16/04/28 19:56:45 INFO Executor: Running task 0.0 in stage 5.0 (TID 4)\n",
      "16/04/28 19:56:45 INFO Executor: Running task 1.0 in stage 5.0 (TID 5)\n",
      "16/04/28 19:56:45 INFO BlockManager: Found block rdd_2_0 locally\n",
      "16/04/28 19:56:45 INFO BlockManager: Found block rdd_2_1 locally\n",
      "16/04/28 19:56:45 INFO Executor: Finished task 1.0 in stage 4.0 (TID 3). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:45 INFO Executor: Finished task 1.0 in stage 5.0 (TID 5). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:45 INFO Executor: Finished task 0.0 in stage 4.0 (TID 2). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:45 INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:45 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 2) in 695 ms on localhost (1/2)\n",
      "16/04/28 19:56:45 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 5) in 518 ms on localhost (1/2)\n",
      "16/04/28 19:56:45 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 3) in 698 ms on localhost (2/2)\n",
      "16/04/28 19:56:45 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:45 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 541 ms on localhost (2/2)\n",
      "16/04/28 19:56:45 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:45 INFO DAGScheduler: ShuffleMapStage 4 (mapPartitions at VertexRDD.scala:358) finished in 0.751 s\n",
      "16/04/28 19:56:45 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:45 INFO DAGScheduler: running: Set(ShuffleMapStage 5)\n",
      "16/04/28 19:56:46 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 6, ShuffleMapStage 3, ShuffleMapStage 7, ShuffleMapStage 8)\n",
      "16/04/28 19:56:46 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:46 INFO DAGScheduler: ShuffleMapStage 5 (mapPartitions at GraphImpl.scala:235) finished in 0.653 s\n",
      "16/04/28 19:56:46 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:46 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:46 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 6, ShuffleMapStage 3, ShuffleMapStage 7, ShuffleMapStage 8)\n",
      "16/04/28 19:56:46 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:46 INFO DAGScheduler: Submitting ShuffleMapStage 3 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[19] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:46 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.8 KB, free 196.2 KB)\n",
      "16/04/28 19:56:46 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 198.9 KB)\n",
      "16/04/28 19:56:46 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:40918 (size: 2.6 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:46 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 3 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[19] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:46 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks\n",
      "16/04/28 19:56:46 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, partition 0,NODE_LOCAL, 2157 bytes)\n",
      "16/04/28 19:56:46 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, partition 1,NODE_LOCAL, 2157 bytes)\n",
      "16/04/28 19:56:46 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)\n",
      "16/04/28 19:56:46 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)\n",
      "16/04/28 19:56:46 INFO DAGScheduler: Submitting ShuffleMapStage 6 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[29] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:46 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.7 KB, free 204.6 KB)\n",
      "16/04/28 19:56:46 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.0 KB, free 207.5 KB)\n",
      "16/04/28 19:56:46 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:40918 (size: 3.0 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:46 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[29] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:46 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks\n",
      "16/04/28 19:56:46 INFO CacheManager: Partition rdd_15_1 not found, computing it\n",
      "16/04/28 19:56:46 INFO CacheManager: Partition rdd_15_0 not found, computing it\n",
      "16/04/28 19:56:46 INFO CacheManager: Partition rdd_8_0 not found, computing it\n",
      "16/04/28 19:56:46 INFO CacheManager: Partition rdd_8_1 not found, computing it\n",
      "16/04/28 19:56:46 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, localhost, partition 0,NODE_LOCAL, 2157 bytes)\n",
      "16/04/28 19:56:46 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, localhost, partition 1,NODE_LOCAL, 2157 bytes)\n",
      "16/04/28 19:56:46 INFO Executor: Running task 0.0 in stage 6.0 (TID 8)\n",
      "16/04/28 19:56:46 INFO Executor: Running task 1.0 in stage 6.0 (TID 9)\n",
      "16/04/28 19:56:46 INFO CacheManager: Partition rdd_25_0 not found, computing it\n",
      "16/04/28 19:56:46 INFO CacheManager: Another thread is loading rdd_15_0, waiting for it to finish...\n",
      "16/04/28 19:56:46 INFO CacheManager: Partition rdd_25_1 not found, computing it\n",
      "16/04/28 19:56:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 49 ms\n",
      "16/04/28 19:56:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 67 ms\n",
      "16/04/28 19:56:46 INFO CacheManager: Another thread is loading rdd_15_1, waiting for it to finish...\n",
      "16/04/28 19:56:46 INFO MemoryStore: Block rdd_8_1 stored as values in memory (estimated size 1504.0 B, free 209.0 KB)\n",
      "16/04/28 19:56:46 INFO BlockManagerInfo: Added rdd_8_1 in memory on localhost:40918 (size: 1504.0 B, free: 517.4 MB)\n",
      "16/04/28 19:56:46 INFO BlockManager: Found block rdd_8_1 locally\n",
      "16/04/28 19:56:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:46 INFO MemoryStore: Block rdd_8_0 stored as values in memory (estimated size 1496.0 B, free 210.5 KB)\n",
      "16/04/28 19:56:46 INFO BlockManagerInfo: Added rdd_8_0 in memory on localhost:40918 (size: 1496.0 B, free: 517.4 MB)\n",
      "16/04/28 19:56:46 INFO BlockManager: Found block rdd_8_0 locally\n",
      "16/04/28 19:56:46 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "16/04/28 19:56:46 INFO MemoryStore: Block rdd_15_1 stored as values in memory (estimated size 1504.0 B, free 211.9 KB)\n",
      "16/04/28 19:56:46 INFO BlockManagerInfo: Added rdd_15_1 in memory on localhost:40918 (size: 1504.0 B, free: 517.4 MB)\n",
      "16/04/28 19:56:46 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 1496.0 B, free 213.4 KB)\n",
      "16/04/28 19:56:46 INFO CacheManager: Finished waiting for rdd_15_1\n",
      "16/04/28 19:56:46 INFO BlockManager: Found block rdd_15_1 locally\n",
      "16/04/28 19:56:46 INFO MemoryStore: Block rdd_25_1 stored as values in memory (estimated size 1768.0 B, free 215.1 KB)\n",
      "16/04/28 19:56:46 INFO BlockManagerInfo: Added rdd_15_0 in memory on localhost:40918 (size: 1496.0 B, free: 517.4 MB)\n",
      "16/04/28 19:56:46 INFO CacheManager: Finished waiting for rdd_15_0\n",
      "16/04/28 19:56:46 INFO BlockManager: Found block rdd_15_0 locally\n",
      "16/04/28 19:56:46 INFO MemoryStore: Block rdd_25_0 stored as values in memory (estimated size 1760.0 B, free 216.8 KB)\n",
      "16/04/28 19:56:46 INFO BlockManagerInfo: Added rdd_25_1 in memory on localhost:40918 (size: 1768.0 B, free: 517.4 MB)\n",
      "16/04/28 19:56:46 INFO BlockManagerInfo: Added rdd_25_0 in memory on localhost:40918 (size: 1760.0 B, free: 517.4 MB)\n",
      "16/04/28 19:56:47 INFO Executor: Finished task 1.0 in stage 6.0 (TID 9). 1739 bytes result sent to driver\n",
      "16/04/28 19:56:47 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 591 ms on localhost (1/2)\n",
      "16/04/28 19:56:47 INFO Executor: Finished task 0.0 in stage 6.0 (TID 8). 1739 bytes result sent to driver\n",
      "16/04/28 19:56:47 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 619 ms on localhost (2/2)\n",
      "16/04/28 19:56:47 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:47 INFO DAGScheduler: ShuffleMapStage 6 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.592 s\n",
      "16/04/28 19:56:47 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:47 INFO DAGScheduler: running: Set(ShuffleMapStage 3)\n",
      "16/04/28 19:56:47 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 7, ShuffleMapStage 8)\n",
      "16/04/28 19:56:47 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:47 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 3105 bytes result sent to driver\n",
      "16/04/28 19:56:47 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 3105 bytes result sent to driver\n",
      "16/04/28 19:56:47 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 906 ms on localhost (1/2)\n",
      "16/04/28 19:56:47 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 896 ms on localhost (2/2)\n",
      "16/04/28 19:56:47 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:47 INFO DAGScheduler: ShuffleMapStage 3 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.936 s\n",
      "16/04/28 19:56:47 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:47 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:47 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 7, ShuffleMapStage 8)\n",
      "16/04/28 19:56:47 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:47 INFO DAGScheduler: Submitting ShuffleMapStage 7 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[33] at mapPartitions at GraphImpl.scala:235), which has no missing parents\n",
      "16/04/28 19:56:47 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.4 KB, free 223.3 KB)\n",
      "16/04/28 19:56:47 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.4 KB, free 226.6 KB)\n",
      "16/04/28 19:56:47 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:40918 (size: 3.4 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:47 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[33] at mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:47 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks\n",
      "16/04/28 19:56:47 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2497 bytes)\n",
      "16/04/28 19:56:47 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2497 bytes)\n",
      "16/04/28 19:56:47 INFO Executor: Running task 0.0 in stage 7.0 (TID 10)\n",
      "16/04/28 19:56:47 INFO Executor: Running task 1.0 in stage 7.0 (TID 11)\n",
      "16/04/28 19:56:47 INFO CacheManager: Partition rdd_27_0 not found, computing it\n",
      "16/04/28 19:56:47 INFO CacheManager: Partition rdd_17_0 not found, computing it\n",
      "16/04/28 19:56:47 INFO BlockManager: Found block rdd_2_0 locally\n",
      "16/04/28 19:56:47 INFO CacheManager: Partition rdd_27_1 not found, computing it\n",
      "16/04/28 19:56:47 INFO CacheManager: Partition rdd_17_1 not found, computing it\n",
      "16/04/28 19:56:47 INFO BlockManager: Found block rdd_2_1 locally\n",
      "16/04/28 19:56:47 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 2.6 KB, free 229.2 KB)\n",
      "16/04/28 19:56:47 INFO MemoryStore: Block rdd_17_1 stored as values in memory (estimated size 2.5 KB, free 231.7 KB)\n",
      "16/04/28 19:56:47 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:47 INFO BlockManagerInfo: Added rdd_17_1 in memory on localhost:40918 (size: 2.5 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "16/04/28 19:56:47 INFO MemoryStore: Block rdd_27_1 stored as values in memory (estimated size 2.6 KB, free 234.4 KB)\n",
      "16/04/28 19:56:47 INFO MemoryStore: Block rdd_27_0 stored as values in memory (estimated size 2.6 KB, free 237.0 KB)\n",
      "16/04/28 19:56:47 INFO BlockManagerInfo: Added rdd_27_1 in memory on localhost:40918 (size: 2.6 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "16/04/28 19:56:47 INFO BlockManagerInfo: Added rdd_27_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "16/04/28 19:56:47 INFO Executor: Finished task 0.0 in stage 7.0 (TID 10). 3105 bytes result sent to driver\n",
      "16/04/28 19:56:47 INFO Executor: Finished task 1.0 in stage 7.0 (TID 11). 3105 bytes result sent to driver\n",
      "16/04/28 19:56:47 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 355 ms on localhost (1/2)\n",
      "16/04/28 19:56:47 INFO DAGScheduler: ShuffleMapStage 7 (mapPartitions at GraphImpl.scala:235) finished in 0.359 s\n",
      "16/04/28 19:56:47 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:47 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:47 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 8)\n",
      "16/04/28 19:56:47 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:47 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 365 ms on localhost (2/2)\n",
      "16/04/28 19:56:47 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:47 INFO DAGScheduler: Submitting ShuffleMapStage 8 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[41] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:47 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 6.7 KB, free 243.7 KB)\n",
      "16/04/28 19:56:47 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.2 KB, free 246.9 KB)\n",
      "16/04/28 19:56:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:40918 (size: 3.2 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:47 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 8 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[41] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:47 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks\n",
      "16/04/28 19:56:47 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 12, localhost, partition 0,PROCESS_LOCAL, 2262 bytes)\n",
      "16/04/28 19:56:47 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 13, localhost, partition 1,PROCESS_LOCAL, 2262 bytes)\n",
      "16/04/28 19:56:47 INFO Executor: Running task 0.0 in stage 8.0 (TID 12)\n",
      "16/04/28 19:56:47 INFO Executor: Running task 1.0 in stage 8.0 (TID 13)\n",
      "16/04/28 19:56:47 INFO BlockManager: Found block rdd_25_0 locally\n",
      "16/04/28 19:56:47 INFO BlockManager: Found block rdd_25_1 locally\n",
      "16/04/28 19:56:47 INFO CacheManager: Partition rdd_37_1 not found, computing it\n",
      "16/04/28 19:56:47 INFO BlockManager: Found block rdd_25_1 locally\n",
      "16/04/28 19:56:47 INFO BlockManager: Found block rdd_25_1 locally\n",
      "16/04/28 19:56:47 INFO CacheManager: Partition rdd_37_0 not found, computing it\n",
      "16/04/28 19:56:47 INFO BlockManager: Found block rdd_25_0 locally\n",
      "16/04/28 19:56:47 INFO BlockManager: Found block rdd_25_0 locally\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms\n",
      "16/04/28 19:56:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:48 INFO MemoryStore: Block rdd_37_0 stored as values in memory (estimated size 1760.0 B, free 248.6 KB)\n",
      "16/04/28 19:56:48 INFO MemoryStore: Block rdd_37_1 stored as values in memory (estimated size 1768.0 B, free 250.4 KB)\n",
      "16/04/28 19:56:48 INFO BlockManagerInfo: Added rdd_37_1 in memory on localhost:40918 (size: 1768.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:48 INFO BlockManagerInfo: Added rdd_37_0 in memory on localhost:40918 (size: 1760.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:48 INFO Executor: Finished task 0.0 in stage 8.0 (TID 12). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:48 INFO Executor: Finished task 1.0 in stage 8.0 (TID 13). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:48 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 12) in 219 ms on localhost (1/2)\n",
      "16/04/28 19:56:48 INFO DAGScheduler: ShuffleMapStage 8 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.220 s\n",
      "16/04/28 19:56:48 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:48 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:48 INFO DAGScheduler: waiting: Set(ResultStage 9)\n",
      "16/04/28 19:56:48 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:48 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 13) in 223 ms on localhost (2/2)\n",
      "16/04/28 19:56:48 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:48 INFO DAGScheduler: Submitting ResultStage 9 (EdgeRDDImpl[44] at RDD at EdgeRDD.scala:40), which has no missing parents\n",
      "16/04/28 19:56:48 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.9 KB, free 257.2 KB)\n",
      "16/04/28 19:56:48 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.5 KB, free 260.8 KB)\n",
      "16/04/28 19:56:48 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:40918 (size: 3.5 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:48 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 9 (EdgeRDDImpl[44] at RDD at EdgeRDD.scala:40)\n",
      "16/04/28 19:56:48 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks\n",
      "16/04/28 19:56:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2549 bytes)\n",
      "16/04/28 19:56:48 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2549 bytes)\n",
      "16/04/28 19:56:48 INFO Executor: Running task 0.0 in stage 9.0 (TID 14)\n",
      "16/04/28 19:56:48 INFO Executor: Running task 1.0 in stage 9.0 (TID 15)\n",
      "16/04/28 19:56:48 INFO CacheManager: Partition rdd_43_1 not found, computing it\n",
      "16/04/28 19:56:48 INFO BlockManager: Found block rdd_27_1 locally\n",
      "16/04/28 19:56:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "16/04/28 19:56:48 INFO CacheManager: Partition rdd_43_0 not found, computing it\n",
      "16/04/28 19:56:48 INFO BlockManager: Found block rdd_27_0 locally\n",
      "16/04/28 19:56:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms\n",
      "16/04/28 19:56:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms\n",
      "16/04/28 19:56:48 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "16/04/28 19:56:48 INFO MemoryStore: Block rdd_43_1 stored as values in memory (estimated size 2.6 KB, free 263.4 KB)\n",
      "16/04/28 19:56:48 INFO BlockManagerInfo: Added rdd_43_1 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:48 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 2.6 KB, free 266.1 KB)\n",
      "16/04/28 19:56:48 INFO Executor: Finished task 1.0 in stage 9.0 (TID 15). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:48 INFO BlockManagerInfo: Added rdd_43_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:48 INFO Executor: Finished task 0.0 in stage 9.0 (TID 14). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:48 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 15) in 232 ms on localhost (1/2)\n",
      "16/04/28 19:56:48 INFO DAGScheduler: ResultStage 9 (foreachPartition at PageRank.scala:150) finished in 0.234 s\n",
      "16/04/28 19:56:48 INFO DAGScheduler: Job 1 finished: foreachPartition at PageRank.scala:150, took 3.584197 s\n",
      "16/04/28 19:56:48 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 14) in 264 ms on localhost (2/2)\n",
      "16/04/28 19:56:48 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:48 INFO PageRank: PageRank finished iteration 0.\n",
      "16/04/28 19:56:48 INFO MapPartitionsRDD: Removing RDD 25 from persistence list\n",
      "16/04/28 19:56:48 INFO MapPartitionsRDD: Removing RDD 27 from persistence list\n",
      "16/04/28 19:56:48 INFO BlockManager: Removing RDD 25\n",
      "16/04/28 19:56:48 INFO BlockManager: Removing RDD 27\n",
      "16/04/28 19:56:48 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:150\n",
      "16/04/28 19:56:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 155 bytes\n",
      "16/04/28 19:56:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 152 bytes\n",
      "16/04/28 19:56:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes\n",
      "16/04/28 19:56:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 152 bytes\n",
      "16/04/28 19:56:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 155 bytes\n",
      "16/04/28 19:56:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 155 bytes\n",
      "16/04/28 19:56:48 INFO DAGScheduler: Registering RDD 45 (mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:48 INFO DAGScheduler: Registering RDD 53 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:48 INFO DAGScheduler: Got job 2 (foreachPartition at PageRank.scala:150) with 2 output partitions\n",
      "16/04/28 19:56:48 INFO DAGScheduler: Final stage: ResultStage 20 (foreachPartition at PageRank.scala:150)\n",
      "16/04/28 19:56:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 19, ShuffleMapStage 17)\n",
      "16/04/28 19:56:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)\n",
      "16/04/28 19:56:48 INFO DAGScheduler: Submitting ShuffleMapStage 18 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[45] at mapPartitions at GraphImpl.scala:235), which has no missing parents\n",
      "16/04/28 19:56:48 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.8 KB, free 264.1 KB)\n",
      "16/04/28 19:56:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.5 KB, free 267.6 KB)\n",
      "16/04/28 19:56:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:40918 (size: 3.5 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:48 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 18 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[45] at mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:48 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks\n",
      "16/04/28 19:56:48 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2538 bytes)\n",
      "16/04/28 19:56:48 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 17, localhost, partition 1,PROCESS_LOCAL, 2538 bytes)\n",
      "16/04/28 19:56:48 INFO Executor: Running task 0.0 in stage 18.0 (TID 16)\n",
      "16/04/28 19:56:48 INFO Executor: Running task 1.0 in stage 18.0 (TID 17)\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_43_0 locally\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_43_1 locally\n",
      "16/04/28 19:56:49 INFO Executor: Finished task 1.0 in stage 18.0 (TID 17). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 17) in 137 ms on localhost (1/2)\n",
      "16/04/28 19:56:49 INFO Executor: Finished task 0.0 in stage 18.0 (TID 16). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:49 INFO DAGScheduler: ShuffleMapStage 18 (mapPartitions at GraphImpl.scala:235) finished in 0.128 s\n",
      "16/04/28 19:56:49 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:49 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 19, ResultStage 20)\n",
      "16/04/28 19:56:49 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 16) in 162 ms on localhost (2/2)\n",
      "16/04/28 19:56:49 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:49 INFO DAGScheduler: Submitting ShuffleMapStage 19 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[53] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:49 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KB, free 274.7 KB)\n",
      "16/04/28 19:56:49 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.4 KB, free 278.1 KB)\n",
      "16/04/28 19:56:49 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:40918 (size: 3.4 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:49 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 19 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[53] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:49 INFO TaskSchedulerImpl: Adding task set 19.0 with 2 tasks\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 18, localhost, partition 0,PROCESS_LOCAL, 2335 bytes)\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 19, localhost, partition 1,PROCESS_LOCAL, 2335 bytes)\n",
      "16/04/28 19:56:49 INFO Executor: Running task 0.0 in stage 19.0 (TID 18)\n",
      "16/04/28 19:56:49 INFO Executor: Running task 1.0 in stage 19.0 (TID 19)\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_37_0 locally\n",
      "16/04/28 19:56:49 INFO CacheManager: Partition rdd_49_0 not found, computing it\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_37_0 locally\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_37_0 locally\n",
      "16/04/28 19:56:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_37_1 locally\n",
      "16/04/28 19:56:49 INFO CacheManager: Partition rdd_49_1 not found, computing it\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_37_1 locally\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_37_1 locally\n",
      "16/04/28 19:56:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "16/04/28 19:56:49 INFO MemoryStore: Block rdd_49_0 stored as values in memory (estimated size 1760.0 B, free 279.8 KB)\n",
      "16/04/28 19:56:49 INFO BlockManagerInfo: Added rdd_49_0 in memory on localhost:40918 (size: 1760.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:49 INFO MemoryStore: Block rdd_49_1 stored as values in memory (estimated size 1768.0 B, free 281.5 KB)\n",
      "16/04/28 19:56:49 INFO BlockManagerInfo: Added rdd_49_1 in memory on localhost:40918 (size: 1768.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:49 INFO Executor: Finished task 0.0 in stage 19.0 (TID 18). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 18) in 117 ms on localhost (1/2)\n",
      "16/04/28 19:56:49 INFO Executor: Finished task 1.0 in stage 19.0 (TID 19). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:49 INFO DAGScheduler: ShuffleMapStage 19 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.110 s\n",
      "16/04/28 19:56:49 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:49 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:49 INFO DAGScheduler: waiting: Set(ResultStage 20)\n",
      "16/04/28 19:56:49 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 19) in 125 ms on localhost (2/2)\n",
      "16/04/28 19:56:49 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:49 INFO DAGScheduler: Submitting ResultStage 20 (EdgeRDDImpl[56] at RDD at EdgeRDD.scala:40), which has no missing parents\n",
      "16/04/28 19:56:49 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KB, free 288.7 KB)\n",
      "16/04/28 19:56:49 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.6 KB, free 292.3 KB)\n",
      "16/04/28 19:56:49 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:40918 (size: 3.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:49 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 20 (EdgeRDDImpl[56] at RDD at EdgeRDD.scala:40)\n",
      "16/04/28 19:56:49 INFO TaskSchedulerImpl: Adding task set 20.0 with 2 tasks\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2590 bytes)\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2590 bytes)\n",
      "16/04/28 19:56:49 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)\n",
      "16/04/28 19:56:49 INFO Executor: Running task 1.0 in stage 20.0 (TID 21)\n",
      "16/04/28 19:56:49 INFO CacheManager: Partition rdd_55_1 not found, computing it\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_43_1 locally\n",
      "16/04/28 19:56:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:49 INFO CacheManager: Partition rdd_55_0 not found, computing it\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_43_0 locally\n",
      "16/04/28 19:56:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms\n",
      "16/04/28 19:56:49 INFO MemoryStore: Block rdd_55_1 stored as values in memory (estimated size 2.6 KB, free 294.9 KB)\n",
      "16/04/28 19:56:49 INFO BlockManagerInfo: Added rdd_55_1 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:49 INFO Executor: Finished task 1.0 in stage 20.0 (TID 21). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:49 INFO MemoryStore: Block rdd_55_0 stored as values in memory (estimated size 2.6 KB, free 297.6 KB)\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 21) in 108 ms on localhost (1/2)\n",
      "16/04/28 19:56:49 INFO BlockManagerInfo: Added rdd_55_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:49 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:49 INFO DAGScheduler: ResultStage 20 (foreachPartition at PageRank.scala:150) finished in 0.101 s\n",
      "16/04/28 19:56:49 INFO DAGScheduler: Job 2 finished: foreachPartition at PageRank.scala:150, took 0.694034 s\n",
      "16/04/28 19:56:49 INFO PageRank: PageRank finished iteration 1.\n",
      "16/04/28 19:56:49 INFO ZippedPartitionsRDD2: Removing RDD 37 from persistence list\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 136 ms on localhost (2/2)\n",
      "16/04/28 19:56:49 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:49 INFO BlockManager: Removing RDD 37\n",
      "16/04/28 19:56:49 INFO ZippedPartitionsRDD2: Removing RDD 43 from persistence list\n",
      "16/04/28 19:56:49 INFO BlockManager: Removing RDD 43\n",
      "16/04/28 19:56:49 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:150\n",
      "16/04/28 19:56:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 155 bytes\n",
      "16/04/28 19:56:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 152 bytes\n",
      "16/04/28 19:56:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes\n",
      "16/04/28 19:56:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 152 bytes\n",
      "16/04/28 19:56:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 155 bytes\n",
      "16/04/28 19:56:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 155 bytes\n",
      "16/04/28 19:56:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 155 bytes\n",
      "16/04/28 19:56:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 155 bytes\n",
      "16/04/28 19:56:49 INFO DAGScheduler: Registering RDD 57 (mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:49 INFO DAGScheduler: Registering RDD 65 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:49 INFO DAGScheduler: Got job 3 (foreachPartition at PageRank.scala:150) with 2 output partitions\n",
      "16/04/28 19:56:49 INFO DAGScheduler: Final stage: ResultStage 33 (foreachPartition at PageRank.scala:150)\n",
      "16/04/28 19:56:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30, ShuffleMapStage 32, ShuffleMapStage 28, ShuffleMapStage 26, ShuffleMapStage 23)\n",
      "16/04/28 19:56:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)\n",
      "16/04/28 19:56:49 INFO DAGScheduler: Submitting ShuffleMapStage 31 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[57] at mapPartitions at GraphImpl.scala:235), which has no missing parents\n",
      "16/04/28 19:56:49 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.0 KB, free 295.9 KB)\n",
      "16/04/28 19:56:49 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.6 KB, free 299.5 KB)\n",
      "16/04/28 19:56:49 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:40918 (size: 3.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:49 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 31 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[57] at mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:49 INFO TaskSchedulerImpl: Adding task set 31.0 with 2 tasks\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 22, localhost, partition 0,PROCESS_LOCAL, 2579 bytes)\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 23, localhost, partition 1,PROCESS_LOCAL, 2579 bytes)\n",
      "16/04/28 19:56:49 INFO Executor: Running task 0.0 in stage 31.0 (TID 22)\n",
      "16/04/28 19:56:49 INFO Executor: Running task 1.0 in stage 31.0 (TID 23)\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_55_0 locally\n",
      "16/04/28 19:56:49 INFO BlockManager: Found block rdd_55_1 locally\n",
      "16/04/28 19:56:49 INFO Executor: Finished task 0.0 in stage 31.0 (TID 22). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 22) in 144 ms on localhost (1/2)\n",
      "16/04/28 19:56:49 INFO Executor: Finished task 1.0 in stage 31.0 (TID 23). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:49 INFO DAGScheduler: ShuffleMapStage 31 (mapPartitions at GraphImpl.scala:235) finished in 0.162 s\n",
      "16/04/28 19:56:49 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:49 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:49 INFO DAGScheduler: waiting: Set(ResultStage 33, ShuffleMapStage 32)\n",
      "16/04/28 19:56:49 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:49 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 23) in 165 ms on localhost (2/2)\n",
      "16/04/28 19:56:49 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:49 INFO DAGScheduler: Submitting ShuffleMapStage 32 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[65] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:50 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.6 KB, free 307.0 KB)\n",
      "16/04/28 19:56:50 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.5 KB, free 310.5 KB)\n",
      "16/04/28 19:56:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:40918 (size: 3.5 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:50 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 32 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[65] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:50 INFO TaskSchedulerImpl: Adding task set 32.0 with 2 tasks\n",
      "16/04/28 19:56:50 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 2408 bytes)\n",
      "16/04/28 19:56:50 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 2408 bytes)\n",
      "16/04/28 19:56:50 INFO Executor: Running task 0.0 in stage 32.0 (TID 24)\n",
      "16/04/28 19:56:50 INFO Executor: Running task 1.0 in stage 32.0 (TID 25)\n",
      "16/04/28 19:56:50 INFO BlockManager: Found block rdd_49_0 locally\n",
      "16/04/28 19:56:50 INFO BlockManager: Found block rdd_49_1 locally\n",
      "16/04/28 19:56:50 INFO CacheManager: Partition rdd_61_1 not found, computing it\n",
      "16/04/28 19:56:50 INFO BlockManager: Found block rdd_49_1 locally\n",
      "16/04/28 19:56:50 INFO BlockManager: Found block rdd_49_1 locally\n",
      "16/04/28 19:56:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:50 INFO CacheManager: Partition rdd_61_0 not found, computing it\n",
      "16/04/28 19:56:50 INFO BlockManager: Found block rdd_49_0 locally\n",
      "16/04/28 19:56:50 INFO BlockManager: Found block rdd_49_0 locally\n",
      "16/04/28 19:56:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "16/04/28 19:56:50 INFO MemoryStore: Block rdd_61_1 stored as values in memory (estimated size 1768.0 B, free 312.2 KB)\n",
      "16/04/28 19:56:50 INFO BlockManagerInfo: Added rdd_61_1 in memory on localhost:40918 (size: 1768.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:50 INFO MemoryStore: Block rdd_61_0 stored as values in memory (estimated size 1760.0 B, free 314.0 KB)\n",
      "16/04/28 19:56:50 INFO BlockManagerInfo: Added rdd_61_0 in memory on localhost:40918 (size: 1760.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:50 INFO Executor: Finished task 1.0 in stage 32.0 (TID 25). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:50 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 25) in 137 ms on localhost (1/2)\n",
      "16/04/28 19:56:50 INFO Executor: Finished task 0.0 in stage 32.0 (TID 24). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:50 INFO DAGScheduler: ShuffleMapStage 32 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.127 s\n",
      "16/04/28 19:56:50 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:50 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:50 INFO DAGScheduler: waiting: Set(ResultStage 33)\n",
      "16/04/28 19:56:50 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:50 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 24) in 149 ms on localhost (2/2)\n",
      "16/04/28 19:56:50 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:50 INFO DAGScheduler: Submitting ResultStage 33 (EdgeRDDImpl[68] at RDD at EdgeRDD.scala:40), which has no missing parents\n",
      "16/04/28 19:56:50 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.4 KB, free 321.4 KB)\n",
      "16/04/28 19:56:50 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 325.1 KB)\n",
      "16/04/28 19:56:50 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:40918 (size: 3.7 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:50 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 33 (EdgeRDDImpl[68] at RDD at EdgeRDD.scala:40)\n",
      "16/04/28 19:56:50 INFO TaskSchedulerImpl: Adding task set 33.0 with 2 tasks\n",
      "16/04/28 19:56:50 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 26, localhost, partition 0,PROCESS_LOCAL, 2631 bytes)\n",
      "16/04/28 19:56:50 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 27, localhost, partition 1,PROCESS_LOCAL, 2631 bytes)\n",
      "16/04/28 19:56:50 INFO Executor: Running task 0.0 in stage 33.0 (TID 26)\n",
      "16/04/28 19:56:50 INFO Executor: Running task 1.0 in stage 33.0 (TID 27)\n",
      "16/04/28 19:56:50 INFO CacheManager: Partition rdd_67_1 not found, computing it\n",
      "16/04/28 19:56:50 INFO BlockManager: Found block rdd_55_1 locally\n",
      "16/04/28 19:56:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:50 INFO CacheManager: Partition rdd_67_0 not found, computing it\n",
      "16/04/28 19:56:50 INFO BlockManager: Found block rdd_55_0 locally\n",
      "16/04/28 19:56:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:50 INFO MemoryStore: Block rdd_67_1 stored as values in memory (estimated size 2.6 KB, free 327.7 KB)\n",
      "16/04/28 19:56:50 INFO BlockManagerInfo: Added rdd_67_1 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:50 INFO MemoryStore: Block rdd_67_0 stored as values in memory (estimated size 2.6 KB, free 330.4 KB)\n",
      "16/04/28 19:56:50 INFO Executor: Finished task 1.0 in stage 33.0 (TID 27). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:50 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 27) in 107 ms on localhost (1/2)\n",
      "16/04/28 19:56:50 INFO BlockManagerInfo: Added rdd_67_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:50 INFO Executor: Finished task 0.0 in stage 33.0 (TID 26). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:50 INFO DAGScheduler: ResultStage 33 (foreachPartition at PageRank.scala:150) finished in 0.112 s\n",
      "16/04/28 19:56:50 INFO DAGScheduler: Job 3 finished: foreachPartition at PageRank.scala:150, took 0.789229 s\n",
      "16/04/28 19:56:50 INFO PageRank: PageRank finished iteration 2.\n",
      "16/04/28 19:56:50 INFO ZippedPartitionsRDD2: Removing RDD 49 from persistence list\n",
      "16/04/28 19:56:50 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 26) in 143 ms on localhost (2/2)\n",
      "16/04/28 19:56:50 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:50 INFO BlockManager: Removing RDD 49\n",
      "16/04/28 19:56:50 INFO ZippedPartitionsRDD2: Removing RDD 55 from persistence list\n",
      "16/04/28 19:56:50 INFO BlockManager: Removing RDD 55\n",
      "16/04/28 19:56:50 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:150\n",
      "16/04/28 19:56:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 155 bytes\n",
      "16/04/28 19:56:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 152 bytes\n",
      "16/04/28 19:56:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes\n",
      "16/04/28 19:56:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 152 bytes\n",
      "16/04/28 19:56:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 155 bytes\n",
      "16/04/28 19:56:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 155 bytes\n",
      "16/04/28 19:56:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 155 bytes\n",
      "16/04/28 19:56:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 155 bytes\n",
      "16/04/28 19:56:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 155 bytes\n",
      "16/04/28 19:56:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 155 bytes\n",
      "16/04/28 19:56:50 INFO DAGScheduler: Registering RDD 69 (mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:50 INFO DAGScheduler: Registering RDD 77 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:50 INFO DAGScheduler: Got job 4 (foreachPartition at PageRank.scala:150) with 2 output partitions\n",
      "16/04/28 19:56:50 INFO DAGScheduler: Final stage: ResultStage 48 (foreachPartition at PageRank.scala:150)\n",
      "16/04/28 19:56:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45, ShuffleMapStage 39, ShuffleMapStage 36, ShuffleMapStage 43, ShuffleMapStage 47, ShuffleMapStage 41)\n",
      "16/04/28 19:56:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 47)\n",
      "16/04/28 19:56:50 INFO DAGScheduler: Submitting ShuffleMapStage 46 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[69] at mapPartitions at GraphImpl.scala:235), which has no missing parents\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.3 KB, free 328.9 KB)\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 332.6 KB)\n",
      "16/04/28 19:56:51 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:40918 (size: 3.7 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:51 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 46 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[69] at mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:51 INFO TaskSchedulerImpl: Adding task set 46.0 with 2 tasks\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 28, localhost, partition 0,PROCESS_LOCAL, 2620 bytes)\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 29, localhost, partition 1,PROCESS_LOCAL, 2620 bytes)\n",
      "16/04/28 19:56:51 INFO Executor: Running task 0.0 in stage 46.0 (TID 28)\n",
      "16/04/28 19:56:51 INFO Executor: Running task 1.0 in stage 46.0 (TID 29)\n",
      "16/04/28 19:56:51 INFO BlockManager: Found block rdd_67_0 locally\n",
      "16/04/28 19:56:51 INFO BlockManager: Found block rdd_67_1 locally\n",
      "16/04/28 19:56:51 INFO Executor: Finished task 1.0 in stage 46.0 (TID 29). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 29) in 83 ms on localhost (1/2)\n",
      "16/04/28 19:56:51 INFO Executor: Finished task 0.0 in stage 46.0 (TID 28). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 28) in 99 ms on localhost (2/2)\n",
      "16/04/28 19:56:51 INFO DAGScheduler: ShuffleMapStage 46 (mapPartitions at GraphImpl.scala:235) finished in 0.074 s\n",
      "16/04/28 19:56:51 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:51 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:51 INFO DAGScheduler: waiting: Set(ResultStage 48, ShuffleMapStage 47)\n",
      "16/04/28 19:56:51 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:51 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:51 INFO DAGScheduler: Submitting ShuffleMapStage 47 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[77] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 8.1 KB, free 340.6 KB)\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.6 KB, free 344.2 KB)\n",
      "16/04/28 19:56:51 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:40918 (size: 3.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:51 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 47 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[77] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:51 INFO TaskSchedulerImpl: Adding task set 47.0 with 2 tasks\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2481 bytes)\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 31, localhost, partition 1,PROCESS_LOCAL, 2481 bytes)\n",
      "16/04/28 19:56:51 INFO Executor: Running task 0.0 in stage 47.0 (TID 30)\n",
      "16/04/28 19:56:51 INFO Executor: Running task 1.0 in stage 47.0 (TID 31)\n",
      "16/04/28 19:56:51 INFO BlockManager: Found block rdd_61_0 locally\n",
      "16/04/28 19:56:51 INFO CacheManager: Partition rdd_73_0 not found, computing it\n",
      "16/04/28 19:56:51 INFO BlockManager: Found block rdd_61_0 locally\n",
      "16/04/28 19:56:51 INFO BlockManager: Found block rdd_61_0 locally\n",
      "16/04/28 19:56:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "16/04/28 19:56:51 INFO BlockManager: Found block rdd_61_1 locally\n",
      "16/04/28 19:56:51 INFO CacheManager: Partition rdd_73_1 not found, computing it\n",
      "16/04/28 19:56:51 INFO BlockManager: Found block rdd_61_1 locally\n",
      "16/04/28 19:56:51 INFO BlockManager: Found block rdd_61_1 locally\n",
      "16/04/28 19:56:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block rdd_73_0 stored as values in memory (estimated size 1760.0 B, free 345.9 KB)\n",
      "16/04/28 19:56:51 INFO BlockManagerInfo: Added rdd_73_0 in memory on localhost:40918 (size: 1760.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block rdd_73_1 stored as values in memory (estimated size 1768.0 B, free 347.6 KB)\n",
      "16/04/28 19:56:51 INFO BlockManagerInfo: Added rdd_73_1 in memory on localhost:40918 (size: 1768.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:51 INFO Executor: Finished task 0.0 in stage 47.0 (TID 30). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 30) in 136 ms on localhost (1/2)\n",
      "16/04/28 19:56:51 INFO Executor: Finished task 1.0 in stage 47.0 (TID 31). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:51 INFO DAGScheduler: ShuffleMapStage 47 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.123 s\n",
      "16/04/28 19:56:51 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:51 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:51 INFO DAGScheduler: waiting: Set(ResultStage 48)\n",
      "16/04/28 19:56:51 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 31) in 139 ms on localhost (2/2)\n",
      "16/04/28 19:56:51 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:51 INFO DAGScheduler: Submitting ResultStage 48 (EdgeRDDImpl[80] at RDD at EdgeRDD.scala:40), which has no missing parents\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.7 KB, free 355.3 KB)\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.8 KB, free 359.1 KB)\n",
      "16/04/28 19:56:51 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:40918 (size: 3.8 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:51 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 48 (EdgeRDDImpl[80] at RDD at EdgeRDD.scala:40)\n",
      "16/04/28 19:56:51 INFO TaskSchedulerImpl: Adding task set 48.0 with 2 tasks\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 32, localhost, partition 0,PROCESS_LOCAL, 2672 bytes)\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 33, localhost, partition 1,PROCESS_LOCAL, 2672 bytes)\n",
      "16/04/28 19:56:51 INFO Executor: Running task 0.0 in stage 48.0 (TID 32)\n",
      "16/04/28 19:56:51 INFO Executor: Running task 1.0 in stage 48.0 (TID 33)\n",
      "16/04/28 19:56:51 INFO CacheManager: Partition rdd_79_1 not found, computing it\n",
      "16/04/28 19:56:51 INFO BlockManager: Found block rdd_67_1 locally\n",
      "16/04/28 19:56:51 INFO CacheManager: Partition rdd_79_0 not found, computing it\n",
      "16/04/28 19:56:51 INFO BlockManager: Found block rdd_67_0 locally\n",
      "16/04/28 19:56:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:51 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "16/04/28 19:56:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block rdd_79_0 stored as values in memory (estimated size 2.6 KB, free 361.7 KB)\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block rdd_79_1 stored as values in memory (estimated size 2.6 KB, free 364.4 KB)\n",
      "16/04/28 19:56:51 INFO BlockManagerInfo: Added rdd_79_1 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:51 INFO Executor: Finished task 1.0 in stage 48.0 (TID 33). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:51 INFO BlockManagerInfo: Added rdd_79_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:51 INFO Executor: Finished task 0.0 in stage 48.0 (TID 32). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 32) in 99 ms on localhost (1/2)\n",
      "16/04/28 19:56:51 INFO DAGScheduler: ResultStage 48 (foreachPartition at PageRank.scala:150) finished in 0.079 s\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Job 4 finished: foreachPartition at PageRank.scala:150, took 0.744606 s\n",
      "16/04/28 19:56:51 INFO PageRank: PageRank finished iteration 3.\n",
      "16/04/28 19:56:51 INFO ZippedPartitionsRDD2: Removing RDD 61 from persistence list\n",
      "16/04/28 19:56:51 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 33) in 106 ms on localhost (2/2)\n",
      "16/04/28 19:56:51 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:51 INFO BlockManager: Removing RDD 61\n",
      "16/04/28 19:56:51 INFO ZippedPartitionsRDD2: Removing RDD 67 from persistence list\n",
      "16/04/28 19:56:51 INFO BlockManager: Removing RDD 67\n",
      "16/04/28 19:56:51 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:150\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 155 bytes\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 152 bytes\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 152 bytes\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 155 bytes\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 155 bytes\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 155 bytes\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 155 bytes\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 155 bytes\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 155 bytes\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 155 bytes\n",
      "16/04/28 19:56:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 155 bytes\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Registering RDD 81 (mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Registering RDD 89 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Got job 5 (foreachPartition at PageRank.scala:150) with 2 output partitions\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Final stage: ResultStage 65 (foreachPartition at PageRank.scala:150)\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51, ShuffleMapStage 60, ShuffleMapStage 64, ShuffleMapStage 56, ShuffleMapStage 54, ShuffleMapStage 58, ShuffleMapStage 62)\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 64)\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Submitting ShuffleMapStage 63 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[81] at mapPartitions at GraphImpl.scala:235), which has no missing parents\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 7.5 KB, free 363.2 KB)\n",
      "16/04/28 19:56:51 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.9 KB)\n",
      "16/04/28 19:56:51 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:40918 (size: 3.7 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:51 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:51 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 63 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[81] at mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:51 INFO TaskSchedulerImpl: Adding task set 63.0 with 2 tasks\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 34, localhost, partition 0,PROCESS_LOCAL, 2661 bytes)\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 35, localhost, partition 1,PROCESS_LOCAL, 2661 bytes)\n",
      "16/04/28 19:56:52 INFO Executor: Running task 0.0 in stage 63.0 (TID 34)\n",
      "16/04/28 19:56:52 INFO Executor: Running task 1.0 in stage 63.0 (TID 35)\n",
      "16/04/28 19:56:52 INFO BlockManager: Found block rdd_79_0 locally\n",
      "16/04/28 19:56:52 INFO BlockManager: Found block rdd_79_1 locally\n",
      "16/04/28 19:56:52 INFO Executor: Finished task 1.0 in stage 63.0 (TID 35). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 35) in 92 ms on localhost (1/2)\n",
      "16/04/28 19:56:52 INFO Executor: Finished task 0.0 in stage 63.0 (TID 34). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 34) in 109 ms on localhost (2/2)\n",
      "16/04/28 19:56:52 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:52 INFO DAGScheduler: ShuffleMapStage 63 (mapPartitions at GraphImpl.scala:235) finished in 0.084 s\n",
      "16/04/28 19:56:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:52 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:52 INFO DAGScheduler: waiting: Set(ShuffleMapStage 64, ResultStage 65)\n",
      "16/04/28 19:56:52 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:52 INFO DAGScheduler: Submitting ShuffleMapStage 64 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[89] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:52 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.5 KB, free 375.5 KB)\n",
      "16/04/28 19:56:52 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 379.1 KB)\n",
      "16/04/28 19:56:52 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:40918 (size: 3.7 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:52 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 64 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[89] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:52 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 36, localhost, partition 0,PROCESS_LOCAL, 2554 bytes)\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 37, localhost, partition 1,PROCESS_LOCAL, 2554 bytes)\n",
      "16/04/28 19:56:52 INFO Executor: Running task 0.0 in stage 64.0 (TID 36)\n",
      "16/04/28 19:56:52 INFO Executor: Running task 1.0 in stage 64.0 (TID 37)\n",
      "16/04/28 19:56:52 INFO BlockManager: Found block rdd_73_1 locally\n",
      "16/04/28 19:56:52 INFO BlockManager: Found block rdd_73_0 locally\n",
      "16/04/28 19:56:52 INFO CacheManager: Partition rdd_85_0 not found, computing it\n",
      "16/04/28 19:56:52 INFO CacheManager: Partition rdd_85_1 not found, computing it\n",
      "16/04/28 19:56:52 INFO BlockManager: Found block rdd_73_1 locally\n",
      "16/04/28 19:56:52 INFO BlockManager: Found block rdd_73_1 locally\n",
      "16/04/28 19:56:52 INFO BlockManager: Found block rdd_73_0 locally\n",
      "16/04/28 19:56:52 INFO BlockManager: Found block rdd_73_0 locally\n",
      "16/04/28 19:56:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms\n",
      "16/04/28 19:56:52 INFO MemoryStore: Block rdd_85_1 stored as values in memory (estimated size 1768.0 B, free 380.8 KB)\n",
      "16/04/28 19:56:52 INFO BlockManagerInfo: Added rdd_85_1 in memory on localhost:40918 (size: 1768.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:52 INFO MemoryStore: Block rdd_85_0 stored as values in memory (estimated size 1760.0 B, free 382.6 KB)\n",
      "16/04/28 19:56:52 INFO BlockManagerInfo: Added rdd_85_0 in memory on localhost:40918 (size: 1760.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:52 INFO Executor: Finished task 1.0 in stage 64.0 (TID 37). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 37) in 142 ms on localhost (1/2)\n",
      "16/04/28 19:56:52 INFO Executor: Finished task 0.0 in stage 64.0 (TID 36). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 36) in 155 ms on localhost (2/2)\n",
      "16/04/28 19:56:52 INFO DAGScheduler: ShuffleMapStage 64 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.128 s\n",
      "16/04/28 19:56:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:52 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:52 INFO DAGScheduler: waiting: Set(ResultStage 65)\n",
      "16/04/28 19:56:52 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:52 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:52 INFO DAGScheduler: Submitting ResultStage 65 (EdgeRDDImpl[92] at RDD at EdgeRDD.scala:40), which has no missing parents\n",
      "16/04/28 19:56:52 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.9 KB, free 390.5 KB)\n",
      "16/04/28 19:56:52 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.9 KB, free 394.4 KB)\n",
      "16/04/28 19:56:52 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:40918 (size: 3.9 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:52 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 65 (EdgeRDDImpl[92] at RDD at EdgeRDD.scala:40)\n",
      "16/04/28 19:56:52 INFO TaskSchedulerImpl: Adding task set 65.0 with 2 tasks\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 38, localhost, partition 0,PROCESS_LOCAL, 2713 bytes)\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 39, localhost, partition 1,PROCESS_LOCAL, 2713 bytes)\n",
      "16/04/28 19:56:52 INFO Executor: Running task 0.0 in stage 65.0 (TID 38)\n",
      "16/04/28 19:56:52 INFO Executor: Running task 1.0 in stage 65.0 (TID 39)\n",
      "16/04/28 19:56:52 INFO CacheManager: Partition rdd_91_0 not found, computing it\n",
      "16/04/28 19:56:52 INFO BlockManager: Found block rdd_79_0 locally\n",
      "16/04/28 19:56:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:52 INFO CacheManager: Partition rdd_91_1 not found, computing it\n",
      "16/04/28 19:56:52 INFO BlockManager: Found block rdd_79_1 locally\n",
      "16/04/28 19:56:52 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms\n",
      "16/04/28 19:56:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "16/04/28 19:56:52 INFO MemoryStore: Block rdd_91_0 stored as values in memory (estimated size 2.6 KB, free 397.0 KB)\n",
      "16/04/28 19:56:52 INFO MemoryStore: Block rdd_91_1 stored as values in memory (estimated size 2.6 KB, free 399.6 KB)\n",
      "16/04/28 19:56:52 INFO BlockManagerInfo: Added rdd_91_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:52 INFO BlockManagerInfo: Added rdd_91_1 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:52 INFO Executor: Finished task 0.0 in stage 65.0 (TID 38). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:52 INFO Executor: Finished task 1.0 in stage 65.0 (TID 39). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 38) in 99 ms on localhost (1/2)\n",
      "16/04/28 19:56:52 INFO DAGScheduler: ResultStage 65 (foreachPartition at PageRank.scala:150) finished in 0.086 s\n",
      "16/04/28 19:56:52 INFO DAGScheduler: Job 5 finished: foreachPartition at PageRank.scala:150, took 0.860249 s\n",
      "16/04/28 19:56:52 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 39) in 108 ms on localhost (2/2)\n",
      "16/04/28 19:56:52 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:52 INFO PageRank: PageRank finished iteration 4.\n",
      "16/04/28 19:56:52 INFO ZippedPartitionsRDD2: Removing RDD 73 from persistence list\n",
      "16/04/28 19:56:52 INFO BlockManager: Removing RDD 73\n",
      "16/04/28 19:56:52 INFO ZippedPartitionsRDD2: Removing RDD 79 from persistence list\n",
      "16/04/28 19:56:52 INFO BlockManager: Removing RDD 79\n",
      "16/04/28 19:56:52 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:150\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 155 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 152 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 152 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 155 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 155 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 155 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 155 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 155 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 155 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 155 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 155 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 155 bytes\n",
      "16/04/28 19:56:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 155 bytes\n",
      "16/04/28 19:56:52 INFO DAGScheduler: Registering RDD 93 (mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Registering RDD 101 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Got job 6 (foreachPartition at PageRank.scala:150) with 2 output partitions\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Final stage: ResultStage 84 (foreachPartition at PageRank.scala:150)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81, ShuffleMapStage 71, ShuffleMapStage 68, ShuffleMapStage 83, ShuffleMapStage 75, ShuffleMapStage 79, ShuffleMapStage 73, ShuffleMapStage 77)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 83)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Submitting ShuffleMapStage 82 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[93] at mapPartitions at GraphImpl.scala:235), which has no missing parents\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 7.8 KB, free 398.7 KB)\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.8 KB, free 402.6 KB)\n",
      "16/04/28 19:56:53 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:40918 (size: 3.8 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:53 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 82 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[93] at mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:53 INFO TaskSchedulerImpl: Adding task set 82.0 with 2 tasks\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 40, localhost, partition 0,PROCESS_LOCAL, 2702 bytes)\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 41, localhost, partition 1,PROCESS_LOCAL, 2702 bytes)\n",
      "16/04/28 19:56:53 INFO Executor: Running task 0.0 in stage 82.0 (TID 40)\n",
      "16/04/28 19:56:53 INFO Executor: Running task 1.0 in stage 82.0 (TID 41)\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_91_0 locally\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_91_1 locally\n",
      "16/04/28 19:56:53 INFO Executor: Finished task 0.0 in stage 82.0 (TID 40). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 40) in 66 ms on localhost (1/2)\n",
      "16/04/28 19:56:53 INFO Executor: Finished task 1.0 in stage 82.0 (TID 41). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 41) in 67 ms on localhost (2/2)\n",
      "16/04/28 19:56:53 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:53 INFO DAGScheduler: ShuffleMapStage 82 (mapPartitions at GraphImpl.scala:235) finished in 0.052 s\n",
      "16/04/28 19:56:53 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:53 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:53 INFO DAGScheduler: waiting: Set(ResultStage 84, ShuffleMapStage 83)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Submitting ShuffleMapStage 83 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[101] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 9.0 KB, free 411.5 KB)\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.7 KB, free 415.3 KB)\n",
      "16/04/28 19:56:53 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:40918 (size: 3.7 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:53 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 83 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[101] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:53 INFO TaskSchedulerImpl: Adding task set 83.0 with 2 tasks\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 42, localhost, partition 0,PROCESS_LOCAL, 2627 bytes)\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 43, localhost, partition 1,PROCESS_LOCAL, 2627 bytes)\n",
      "16/04/28 19:56:53 INFO Executor: Running task 0.0 in stage 83.0 (TID 42)\n",
      "16/04/28 19:56:53 INFO Executor: Running task 1.0 in stage 83.0 (TID 43)\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_85_0 locally\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_85_1 locally\n",
      "16/04/28 19:56:53 INFO CacheManager: Partition rdd_97_1 not found, computing it\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_85_1 locally\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_85_1 locally\n",
      "16/04/28 19:56:53 INFO CacheManager: Partition rdd_97_0 not found, computing it\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_85_0 locally\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_85_0 locally\n",
      "16/04/28 19:56:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block rdd_97_0 stored as values in memory (estimated size 1760.0 B, free 417.0 KB)\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block rdd_97_1 stored as values in memory (estimated size 1768.0 B, free 418.7 KB)\n",
      "16/04/28 19:56:53 INFO BlockManagerInfo: Added rdd_97_1 in memory on localhost:40918 (size: 1768.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:53 INFO BlockManagerInfo: Added rdd_97_0 in memory on localhost:40918 (size: 1760.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:53 INFO Executor: Finished task 1.0 in stage 83.0 (TID 43). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 43) in 88 ms on localhost (1/2)\n",
      "16/04/28 19:56:53 INFO Executor: Finished task 0.0 in stage 83.0 (TID 42). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 42) in 97 ms on localhost (2/2)\n",
      "16/04/28 19:56:53 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:53 INFO DAGScheduler: ShuffleMapStage 83 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.079 s\n",
      "16/04/28 19:56:53 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:53 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:53 INFO DAGScheduler: waiting: Set(ResultStage 84)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Submitting ResultStage 84 (EdgeRDDImpl[104] at RDD at EdgeRDD.scala:40), which has no missing parents\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 8.2 KB, free 426.9 KB)\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.9 KB, free 430.9 KB)\n",
      "16/04/28 19:56:53 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:40918 (size: 3.9 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:53 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 84 (EdgeRDDImpl[104] at RDD at EdgeRDD.scala:40)\n",
      "16/04/28 19:56:53 INFO TaskSchedulerImpl: Adding task set 84.0 with 2 tasks\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 44, localhost, partition 0,PROCESS_LOCAL, 2754 bytes)\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 45, localhost, partition 1,PROCESS_LOCAL, 2754 bytes)\n",
      "16/04/28 19:56:53 INFO Executor: Running task 0.0 in stage 84.0 (TID 44)\n",
      "16/04/28 19:56:53 INFO Executor: Running task 1.0 in stage 84.0 (TID 45)\n",
      "16/04/28 19:56:53 INFO CacheManager: Partition rdd_103_1 not found, computing it\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_91_1 locally\n",
      "16/04/28 19:56:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "16/04/28 19:56:53 INFO CacheManager: Partition rdd_103_0 not found, computing it\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_91_0 locally\n",
      "16/04/28 19:56:53 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block rdd_103_0 stored as values in memory (estimated size 2.6 KB, free 433.5 KB)\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block rdd_103_1 stored as values in memory (estimated size 2.6 KB, free 436.2 KB)\n",
      "16/04/28 19:56:53 INFO BlockManagerInfo: Added rdd_103_1 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:53 INFO Executor: Finished task 1.0 in stage 84.0 (TID 45). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:53 INFO BlockManagerInfo: Added rdd_103_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 45) in 58 ms on localhost (1/2)\n",
      "16/04/28 19:56:53 INFO Executor: Finished task 0.0 in stage 84.0 (TID 44). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:53 INFO DAGScheduler: ResultStage 84 (foreachPartition at PageRank.scala:150) finished in 0.052 s\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Job 6 finished: foreachPartition at PageRank.scala:150, took 0.675515 s\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 44) in 72 ms on localhost (2/2)\n",
      "16/04/28 19:56:53 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:53 INFO PageRank: PageRank finished iteration 5.\n",
      "16/04/28 19:56:53 INFO ZippedPartitionsRDD2: Removing RDD 85 from persistence list\n",
      "16/04/28 19:56:53 INFO BlockManager: Removing RDD 85\n",
      "16/04/28 19:56:53 INFO ZippedPartitionsRDD2: Removing RDD 91 from persistence list\n",
      "16/04/28 19:56:53 INFO BlockManager: Removing RDD 91\n",
      "16/04/28 19:56:53 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:150\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 152 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 152 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 155 bytes\n",
      "16/04/28 19:56:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 155 bytes\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Registering RDD 105 (mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Registering RDD 113 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Got job 7 (foreachPartition at PageRank.scala:150) with 2 output partitions\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Final stage: ResultStage 105 (foreachPartition at PageRank.scala:150)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102, ShuffleMapStage 96, ShuffleMapStage 100, ShuffleMapStage 104, ShuffleMapStage 90, ShuffleMapStage 87, ShuffleMapStage 94, ShuffleMapStage 98, ShuffleMapStage 92)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Submitting ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[105] at mapPartitions at GraphImpl.scala:235), which has no missing parents\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 8.1 KB, free 435.5 KB)\n",
      "16/04/28 19:56:53 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.9 KB, free 439.4 KB)\n",
      "16/04/28 19:56:53 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:40918 (size: 3.9 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:53 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[105] at mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:53 INFO TaskSchedulerImpl: Adding task set 103.0 with 2 tasks\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 46, localhost, partition 0,PROCESS_LOCAL, 2743 bytes)\n",
      "16/04/28 19:56:53 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 47, localhost, partition 1,PROCESS_LOCAL, 2743 bytes)\n",
      "16/04/28 19:56:53 INFO Executor: Running task 0.0 in stage 103.0 (TID 46)\n",
      "16/04/28 19:56:53 INFO Executor: Running task 1.0 in stage 103.0 (TID 47)\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_103_0 locally\n",
      "16/04/28 19:56:53 INFO BlockManager: Found block rdd_103_1 locally\n",
      "16/04/28 19:56:53 INFO Executor: Finished task 1.0 in stage 103.0 (TID 47). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:53 INFO Executor: Finished task 0.0 in stage 103.0 (TID 46). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 47) in 44 ms on localhost (1/2)\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 46) in 50 ms on localhost (2/2)\n",
      "16/04/28 19:56:54 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:54 INFO DAGScheduler: ShuffleMapStage 103 (mapPartitions at GraphImpl.scala:235) finished in 0.036 s\n",
      "16/04/28 19:56:54 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:54 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 104, ResultStage 105)\n",
      "16/04/28 19:56:54 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Submitting ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[113] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 9.5 KB, free 448.9 KB)\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.8 KB, free 452.7 KB)\n",
      "16/04/28 19:56:54 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:40918 (size: 3.8 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:54 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[113] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:54 INFO TaskSchedulerImpl: Adding task set 104.0 with 2 tasks\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 48, localhost, partition 0,PROCESS_LOCAL, 2700 bytes)\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 49, localhost, partition 1,PROCESS_LOCAL, 2700 bytes)\n",
      "16/04/28 19:56:54 INFO Executor: Running task 0.0 in stage 104.0 (TID 48)\n",
      "16/04/28 19:56:54 INFO Executor: Running task 1.0 in stage 104.0 (TID 49)\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_97_0 locally\n",
      "16/04/28 19:56:54 INFO CacheManager: Partition rdd_109_0 not found, computing it\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_97_0 locally\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_97_0 locally\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_97_1 locally\n",
      "16/04/28 19:56:54 INFO CacheManager: Partition rdd_109_1 not found, computing it\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_97_1 locally\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_97_1 locally\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block rdd_109_1 stored as values in memory (estimated size 1768.0 B, free 454.4 KB)\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block rdd_109_0 stored as values in memory (estimated size 1760.0 B, free 456.1 KB)\n",
      "16/04/28 19:56:54 INFO BlockManagerInfo: Added rdd_109_0 in memory on localhost:40918 (size: 1760.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:54 INFO BlockManagerInfo: Added rdd_109_1 in memory on localhost:40918 (size: 1768.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:54 INFO Executor: Finished task 1.0 in stage 104.0 (TID 49). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 49) in 77 ms on localhost (1/2)\n",
      "16/04/28 19:56:54 INFO Executor: Finished task 0.0 in stage 104.0 (TID 48). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 48) in 102 ms on localhost (2/2)\n",
      "16/04/28 19:56:54 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:54 INFO DAGScheduler: ShuffleMapStage 104 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.077 s\n",
      "16/04/28 19:56:54 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:54 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:54 INFO DAGScheduler: waiting: Set(ResultStage 105)\n",
      "16/04/28 19:56:54 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Submitting ResultStage 105 (EdgeRDDImpl[116] at RDD at EdgeRDD.scala:40), which has no missing parents\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 8.5 KB, free 464.6 KB)\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 4.0 KB, free 468.7 KB)\n",
      "16/04/28 19:56:54 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:40918 (size: 4.0 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:54 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 105 (EdgeRDDImpl[116] at RDD at EdgeRDD.scala:40)\n",
      "16/04/28 19:56:54 INFO TaskSchedulerImpl: Adding task set 105.0 with 2 tasks\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 50, localhost, partition 0,PROCESS_LOCAL, 2795 bytes)\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 51, localhost, partition 1,PROCESS_LOCAL, 2795 bytes)\n",
      "16/04/28 19:56:54 INFO Executor: Running task 0.0 in stage 105.0 (TID 50)\n",
      "16/04/28 19:56:54 INFO Executor: Running task 1.0 in stage 105.0 (TID 51)\n",
      "16/04/28 19:56:54 INFO CacheManager: Partition rdd_115_1 not found, computing it\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_103_1 locally\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms\n",
      "16/04/28 19:56:54 INFO CacheManager: Partition rdd_115_0 not found, computing it\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_103_0 locally\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block rdd_115_1 stored as values in memory (estimated size 2.6 KB, free 471.3 KB)\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block rdd_115_0 stored as values in memory (estimated size 2.6 KB, free 473.9 KB)\n",
      "16/04/28 19:56:54 INFO BlockManagerInfo: Added rdd_115_1 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:54 INFO BlockManagerInfo: Added rdd_115_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:54 INFO Executor: Finished task 1.0 in stage 105.0 (TID 51). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 51) in 98 ms on localhost (1/2)\n",
      "16/04/28 19:56:54 INFO Executor: Finished task 0.0 in stage 105.0 (TID 50). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 50) in 104 ms on localhost (2/2)\n",
      "16/04/28 19:56:54 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:54 INFO DAGScheduler: ResultStage 105 (foreachPartition at PageRank.scala:150) finished in 0.072 s\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Job 7 finished: foreachPartition at PageRank.scala:150, took 0.655185 s\n",
      "16/04/28 19:56:54 INFO PageRank: PageRank finished iteration 6.\n",
      "16/04/28 19:56:54 INFO ZippedPartitionsRDD2: Removing RDD 97 from persistence list\n",
      "16/04/28 19:56:54 INFO ZippedPartitionsRDD2: Removing RDD 103 from persistence list\n",
      "16/04/28 19:56:54 INFO BlockManager: Removing RDD 97\n",
      "16/04/28 19:56:54 INFO BlockManager: Removing RDD 103\n",
      "16/04/28 19:56:54 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:150\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 152 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 152 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 155 bytes\n",
      "16/04/28 19:56:54 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 155 bytes\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Registering RDD 117 (mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Registering RDD 125 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Got job 8 (foreachPartition at PageRank.scala:150) with 2 output partitions\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Final stage: ResultStage 128 (foreachPartition at PageRank.scala:150)\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 121, ShuffleMapStage 115, ShuffleMapStage 125, ShuffleMapStage 119, ShuffleMapStage 111, ShuffleMapStage 108, ShuffleMapStage 123, ShuffleMapStage 127, ShuffleMapStage 113)\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 127)\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Submitting ShuffleMapStage 126 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[117] at mapPartitions at GraphImpl.scala:235), which has no missing parents\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 8.3 KB, free 473.5 KB)\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 4.0 KB, free 477.5 KB)\n",
      "16/04/28 19:56:54 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:40918 (size: 4.0 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:54 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 126 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[117] at mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:54 INFO TaskSchedulerImpl: Adding task set 126.0 with 2 tasks\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 52, localhost, partition 0,PROCESS_LOCAL, 2784 bytes)\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 53, localhost, partition 1,PROCESS_LOCAL, 2784 bytes)\n",
      "16/04/28 19:56:54 INFO Executor: Running task 0.0 in stage 126.0 (TID 52)\n",
      "16/04/28 19:56:54 INFO Executor: Running task 1.0 in stage 126.0 (TID 53)\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_115_0 locally\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_115_1 locally\n",
      "16/04/28 19:56:54 INFO Executor: Finished task 1.0 in stage 126.0 (TID 53). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 53) in 30 ms on localhost (1/2)\n",
      "16/04/28 19:56:54 INFO Executor: Finished task 0.0 in stage 126.0 (TID 52). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 52) in 34 ms on localhost (2/2)\n",
      "16/04/28 19:56:54 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:54 INFO DAGScheduler: ShuffleMapStage 126 (mapPartitions at GraphImpl.scala:235) finished in 0.015 s\n",
      "16/04/28 19:56:54 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:54 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 127, ResultStage 128)\n",
      "16/04/28 19:56:54 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Submitting ShuffleMapStage 127 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[125] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 9.9 KB, free 487.4 KB)\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.0 KB, free 491.4 KB)\n",
      "16/04/28 19:56:54 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:40918 (size: 4.0 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:54 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 127 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[125] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:54 INFO TaskSchedulerImpl: Adding task set 127.0 with 2 tasks\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 54, localhost, partition 0,PROCESS_LOCAL, 2773 bytes)\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Starting task 1.0 in stage 127.0 (TID 55, localhost, partition 1,PROCESS_LOCAL, 2773 bytes)\n",
      "16/04/28 19:56:54 INFO Executor: Running task 0.0 in stage 127.0 (TID 54)\n",
      "16/04/28 19:56:54 INFO Executor: Running task 1.0 in stage 127.0 (TID 55)\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_109_1 locally\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_109_0 locally\n",
      "16/04/28 19:56:54 INFO CacheManager: Partition rdd_121_0 not found, computing it\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_109_0 locally\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_109_0 locally\n",
      "16/04/28 19:56:54 INFO CacheManager: Partition rdd_121_1 not found, computing it\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_109_1 locally\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_109_1 locally\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block rdd_121_1 stored as values in memory (estimated size 1768.0 B, free 493.1 KB)\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block rdd_121_0 stored as values in memory (estimated size 1760.0 B, free 494.8 KB)\n",
      "16/04/28 19:56:54 INFO BlockManagerInfo: Added rdd_121_1 in memory on localhost:40918 (size: 1768.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:54 INFO BlockManagerInfo: Added rdd_121_0 in memory on localhost:40918 (size: 1760.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:54 INFO Executor: Finished task 0.0 in stage 127.0 (TID 54). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:54 INFO Executor: Finished task 1.0 in stage 127.0 (TID 55). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 54) in 74 ms on localhost (1/2)\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Finished task 1.0 in stage 127.0 (TID 55) in 78 ms on localhost (2/2)\n",
      "16/04/28 19:56:54 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:54 INFO DAGScheduler: ShuffleMapStage 127 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.058 s\n",
      "16/04/28 19:56:54 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:54 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:54 INFO DAGScheduler: waiting: Set(ResultStage 128)\n",
      "16/04/28 19:56:54 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Submitting ResultStage 128 (EdgeRDDImpl[128] at RDD at EdgeRDD.scala:40), which has no missing parents\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 8.7 KB, free 503.6 KB)\n",
      "16/04/28 19:56:54 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 4.1 KB, free 507.7 KB)\n",
      "16/04/28 19:56:54 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:40918 (size: 4.1 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:54 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 128 (EdgeRDDImpl[128] at RDD at EdgeRDD.scala:40)\n",
      "16/04/28 19:56:54 INFO TaskSchedulerImpl: Adding task set 128.0 with 2 tasks\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 56, localhost, partition 0,PROCESS_LOCAL, 2836 bytes)\n",
      "16/04/28 19:56:54 INFO TaskSetManager: Starting task 1.0 in stage 128.0 (TID 57, localhost, partition 1,PROCESS_LOCAL, 2836 bytes)\n",
      "16/04/28 19:56:54 INFO Executor: Running task 0.0 in stage 128.0 (TID 56)\n",
      "16/04/28 19:56:54 INFO Executor: Running task 1.0 in stage 128.0 (TID 57)\n",
      "16/04/28 19:56:54 INFO CacheManager: Partition rdd_127_0 not found, computing it\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_115_0 locally\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "16/04/28 19:56:54 INFO CacheManager: Partition rdd_127_1 not found, computing it\n",
      "16/04/28 19:56:54 INFO BlockManager: Found block rdd_115_1 locally\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block rdd_127_0 stored as values in memory (estimated size 2.6 KB, free 510.3 KB)\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block rdd_127_1 stored as values in memory (estimated size 2.6 KB, free 512.9 KB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added rdd_127_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:55 INFO Executor: Finished task 0.0 in stage 128.0 (TID 56). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added rdd_127_1 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 56) in 82 ms on localhost (1/2)\n",
      "16/04/28 19:56:55 INFO Executor: Finished task 1.0 in stage 128.0 (TID 57). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Finished task 1.0 in stage 128.0 (TID 57) in 83 ms on localhost (2/2)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: ResultStage 128 (foreachPartition at PageRank.scala:150) finished in 0.068 s\n",
      "16/04/28 19:56:55 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:55 INFO DAGScheduler: Job 8 finished: foreachPartition at PageRank.scala:150, took 0.560018 s\n",
      "16/04/28 19:56:55 INFO PageRank: PageRank finished iteration 7.\n",
      "16/04/28 19:56:55 INFO ZippedPartitionsRDD2: Removing RDD 109 from persistence list\n",
      "16/04/28 19:56:55 INFO BlockManager: Removing RDD 109\n",
      "16/04/28 19:56:55 INFO ZippedPartitionsRDD2: Removing RDD 115 from persistence list\n",
      "16/04/28 19:56:55 INFO BlockManager: Removing RDD 115\n",
      "16/04/28 19:56:55 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:150\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 152 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 152 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 155 bytes\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Registering RDD 129 (mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Registering RDD 137 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Got job 9 (foreachPartition at PageRank.scala:150) with 2 output partitions\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Final stage: ResultStage 153 (foreachPartition at PageRank.scala:150)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 150, ShuffleMapStage 136, ShuffleMapStage 140, ShuffleMapStage 152, ShuffleMapStage 144, ShuffleMapStage 138, ShuffleMapStage 148, ShuffleMapStage 142, ShuffleMapStage 134, ShuffleMapStage 131, ShuffleMapStage 146)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 152)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Submitting ShuffleMapStage 151 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[129] at mapPartitions at GraphImpl.scala:235), which has no missing parents\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 8.6 KB, free 512.8 KB)\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 4.0 KB, free 516.9 KB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:40918 (size: 4.0 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:55 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 151 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[129] at mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:55 INFO TaskSchedulerImpl: Adding task set 151.0 with 2 tasks\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 58, localhost, partition 0,PROCESS_LOCAL, 2825 bytes)\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Starting task 1.0 in stage 151.0 (TID 59, localhost, partition 1,PROCESS_LOCAL, 2825 bytes)\n",
      "16/04/28 19:56:55 INFO Executor: Running task 0.0 in stage 151.0 (TID 58)\n",
      "16/04/28 19:56:55 INFO Executor: Running task 1.0 in stage 151.0 (TID 59)\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_127_0 locally\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_127_1 locally\n",
      "16/04/28 19:56:55 INFO Executor: Finished task 1.0 in stage 151.0 (TID 59). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:55 INFO Executor: Finished task 0.0 in stage 151.0 (TID 58). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Finished task 1.0 in stage 151.0 (TID 59) in 45 ms on localhost (1/2)\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 58) in 51 ms on localhost (2/2)\n",
      "16/04/28 19:56:55 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:55 INFO DAGScheduler: ShuffleMapStage 151 (mapPartitions at GraphImpl.scala:235) finished in 0.034 s\n",
      "16/04/28 19:56:55 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:55 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:55 INFO DAGScheduler: waiting: Set(ResultStage 153, ShuffleMapStage 152)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Submitting ShuffleMapStage 152 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[137] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 10.4 KB, free 527.2 KB)\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 4.0 KB, free 531.3 KB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:40918 (size: 4.0 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:55 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 152 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[137] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:55 INFO TaskSchedulerImpl: Adding task set 152.0 with 2 tasks\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 60, localhost, partition 0,PROCESS_LOCAL, 2846 bytes)\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Starting task 1.0 in stage 152.0 (TID 61, localhost, partition 1,PROCESS_LOCAL, 2846 bytes)\n",
      "16/04/28 19:56:55 INFO Executor: Running task 0.0 in stage 152.0 (TID 60)\n",
      "16/04/28 19:56:55 INFO Executor: Running task 1.0 in stage 152.0 (TID 61)\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_121_0 locally\n",
      "16/04/28 19:56:55 INFO CacheManager: Partition rdd_133_0 not found, computing it\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_121_0 locally\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_121_0 locally\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_121_1 locally\n",
      "16/04/28 19:56:55 INFO CacheManager: Partition rdd_133_1 not found, computing it\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_121_1 locally\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_121_1 locally\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block rdd_133_0 stored as values in memory (estimated size 1760.0 B, free 533.0 KB)\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block rdd_133_1 stored as values in memory (estimated size 1768.0 B, free 534.7 KB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added rdd_133_0 in memory on localhost:40918 (size: 1760.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added rdd_133_1 in memory on localhost:40918 (size: 1768.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:55 INFO Executor: Finished task 1.0 in stage 152.0 (TID 61). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Finished task 1.0 in stage 152.0 (TID 61) in 57 ms on localhost (1/2)\n",
      "16/04/28 19:56:55 INFO Executor: Finished task 0.0 in stage 152.0 (TID 60). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 60) in 72 ms on localhost (2/2)\n",
      "16/04/28 19:56:55 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:55 INFO DAGScheduler: ShuffleMapStage 152 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.050 s\n",
      "16/04/28 19:56:55 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:55 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:55 INFO DAGScheduler: waiting: Set(ResultStage 153)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Submitting ResultStage 153 (EdgeRDDImpl[140] at RDD at EdgeRDD.scala:40), which has no missing parents\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 9.0 KB, free 543.7 KB)\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 4.2 KB, free 547.9 KB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:40918 (size: 4.2 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:55 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 153 (EdgeRDDImpl[140] at RDD at EdgeRDD.scala:40)\n",
      "16/04/28 19:56:55 INFO TaskSchedulerImpl: Adding task set 153.0 with 2 tasks\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 62, localhost, partition 0,PROCESS_LOCAL, 2877 bytes)\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Starting task 1.0 in stage 153.0 (TID 63, localhost, partition 1,PROCESS_LOCAL, 2877 bytes)\n",
      "16/04/28 19:56:55 INFO Executor: Running task 0.0 in stage 153.0 (TID 62)\n",
      "16/04/28 19:56:55 INFO Executor: Running task 1.0 in stage 153.0 (TID 63)\n",
      "16/04/28 19:56:55 INFO CacheManager: Partition rdd_139_0 not found, computing it\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_127_0 locally\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "16/04/28 19:56:55 INFO CacheManager: Partition rdd_139_1 not found, computing it\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_127_1 locally\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block rdd_139_1 stored as values in memory (estimated size 2.6 KB, free 550.5 KB)\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block rdd_139_0 stored as values in memory (estimated size 2.6 KB, free 553.2 KB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added rdd_139_1 in memory on localhost:40918 (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added rdd_139_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.2 MB)\n",
      "16/04/28 19:56:55 INFO Executor: Finished task 0.0 in stage 153.0 (TID 62). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 62) in 74 ms on localhost (1/2)\n",
      "16/04/28 19:56:55 INFO Executor: Finished task 1.0 in stage 153.0 (TID 63). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Finished task 1.0 in stage 153.0 (TID 63) in 78 ms on localhost (2/2)\n",
      "16/04/28 19:56:55 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:55 INFO DAGScheduler: ResultStage 153 (foreachPartition at PageRank.scala:150) finished in 0.058 s\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Job 9 finished: foreachPartition at PageRank.scala:150, took 0.416517 s\n",
      "16/04/28 19:56:55 INFO PageRank: PageRank finished iteration 8.\n",
      "16/04/28 19:56:55 INFO ZippedPartitionsRDD2: Removing RDD 121 from persistence list\n",
      "16/04/28 19:56:55 INFO BlockManager: Removing RDD 121\n",
      "16/04/28 19:56:55 INFO ZippedPartitionsRDD2: Removing RDD 127 from persistence list\n",
      "16/04/28 19:56:55 INFO BlockManager: Removing RDD 127\n",
      "16/04/28 19:56:55 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:150\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 152 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 152 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 155 bytes\n",
      "16/04/28 19:56:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 20 is 155 bytes\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Registering RDD 141 (mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Registering RDD 149 (mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Got job 10 (foreachPartition at PageRank.scala:150) with 2 output partitions\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Final stage: ResultStage 180 (foreachPartition at PageRank.scala:150)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 179, ShuffleMapStage 161, ShuffleMapStage 171, ShuffleMapStage 165, ShuffleMapStage 169, ShuffleMapStage 173, ShuffleMapStage 177, ShuffleMapStage 159, ShuffleMapStage 156, ShuffleMapStage 163, ShuffleMapStage 175, ShuffleMapStage 167)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 179)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Submitting ShuffleMapStage 178 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[141] at mapPartitions at GraphImpl.scala:235), which has no missing parents\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 8.9 KB, free 553.3 KB)\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 4.1 KB, free 557.4 KB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:40918 (size: 4.1 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:55 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 178 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[141] at mapPartitions at GraphImpl.scala:235)\n",
      "16/04/28 19:56:55 INFO TaskSchedulerImpl: Adding task set 178.0 with 2 tasks\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 64, localhost, partition 0,PROCESS_LOCAL, 2866 bytes)\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Starting task 1.0 in stage 178.0 (TID 65, localhost, partition 1,PROCESS_LOCAL, 2866 bytes)\n",
      "16/04/28 19:56:55 INFO Executor: Running task 0.0 in stage 178.0 (TID 64)\n",
      "16/04/28 19:56:55 INFO Executor: Running task 1.0 in stage 178.0 (TID 65)\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_139_1 locally\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_139_0 locally\n",
      "16/04/28 19:56:55 INFO Executor: Finished task 1.0 in stage 178.0 (TID 65). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Finished task 1.0 in stage 178.0 (TID 65) in 28 ms on localhost (1/2)\n",
      "16/04/28 19:56:55 INFO Executor: Finished task 0.0 in stage 178.0 (TID 64). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 64) in 44 ms on localhost (2/2)\n",
      "16/04/28 19:56:55 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:55 INFO DAGScheduler: ShuffleMapStage 178 (mapPartitions at GraphImpl.scala:235) finished in 0.025 s\n",
      "16/04/28 19:56:55 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:55 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 179, ResultStage 180)\n",
      "16/04/28 19:56:55 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Submitting ShuffleMapStage 179 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[149] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 10.8 KB, free 568.3 KB)\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 4.1 KB, free 572.4 KB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:40918 (size: 4.1 KB, free: 517.2 MB)\n",
      "16/04/28 19:56:55 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 179 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[149] at mapPartitions at VertexRDDImpl.scala:247)\n",
      "16/04/28 19:56:55 INFO TaskSchedulerImpl: Adding task set 179.0 with 2 tasks\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 66, localhost, partition 0,PROCESS_LOCAL, 2919 bytes)\n",
      "16/04/28 19:56:55 INFO TaskSetManager: Starting task 1.0 in stage 179.0 (TID 67, localhost, partition 1,PROCESS_LOCAL, 2919 bytes)\n",
      "16/04/28 19:56:55 INFO Executor: Running task 0.0 in stage 179.0 (TID 66)\n",
      "16/04/28 19:56:55 INFO Executor: Running task 1.0 in stage 179.0 (TID 67)\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_133_0 locally\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_133_1 locally\n",
      "16/04/28 19:56:55 INFO CacheManager: Partition rdd_145_1 not found, computing it\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_133_1 locally\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_133_1 locally\n",
      "16/04/28 19:56:55 INFO CacheManager: Partition rdd_145_0 not found, computing it\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_133_0 locally\n",
      "16/04/28 19:56:55 INFO BlockManager: Found block rdd_133_0 locally\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block rdd_145_0 stored as values in memory (estimated size 1760.0 B, free 574.1 KB)\n",
      "16/04/28 19:56:55 INFO MemoryStore: Block rdd_145_1 stored as values in memory (estimated size 1768.0 B, free 575.8 KB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added rdd_145_0 in memory on localhost:40918 (size: 1760.0 B, free: 517.2 MB)\n",
      "16/04/28 19:56:55 INFO BlockManagerInfo: Added rdd_145_1 in memory on localhost:40918 (size: 1768.0 B, free: 517.2 MB)\n",
      "16/04/28 19:56:55 INFO Executor: Finished task 0.0 in stage 179.0 (TID 66). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:56 INFO Executor: Finished task 1.0 in stage 179.0 (TID 67). 3050 bytes result sent to driver\n",
      "16/04/28 19:56:56 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 66) in 67 ms on localhost (1/2)\n",
      "16/04/28 19:56:56 INFO TaskSetManager: Finished task 1.0 in stage 179.0 (TID 67) in 72 ms on localhost (2/2)\n",
      "16/04/28 19:56:56 INFO DAGScheduler: ShuffleMapStage 179 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.057 s\n",
      "16/04/28 19:56:56 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:56 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:56 INFO DAGScheduler: waiting: Set(ResultStage 180)\n",
      "16/04/28 19:56:56 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:56 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:56 INFO DAGScheduler: Submitting ResultStage 180 (EdgeRDDImpl[152] at RDD at EdgeRDD.scala:40), which has no missing parents\n",
      "16/04/28 19:56:56 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 9.3 KB, free 585.1 KB)\n",
      "16/04/28 19:56:56 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 4.2 KB, free 589.3 KB)\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:40918 (size: 4.2 KB, free: 517.2 MB)\n",
      "16/04/28 19:56:56 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 180 (EdgeRDDImpl[152] at RDD at EdgeRDD.scala:40)\n",
      "16/04/28 19:56:56 INFO TaskSchedulerImpl: Adding task set 180.0 with 2 tasks\n",
      "16/04/28 19:56:56 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 68, localhost, partition 0,PROCESS_LOCAL, 2918 bytes)\n",
      "16/04/28 19:56:56 INFO TaskSetManager: Starting task 1.0 in stage 180.0 (TID 69, localhost, partition 1,PROCESS_LOCAL, 2918 bytes)\n",
      "16/04/28 19:56:56 INFO Executor: Running task 0.0 in stage 180.0 (TID 68)\n",
      "16/04/28 19:56:56 INFO Executor: Running task 1.0 in stage 180.0 (TID 69)\n",
      "16/04/28 19:56:56 INFO CacheManager: Partition rdd_151_1 not found, computing it\n",
      "16/04/28 19:56:56 INFO BlockManager: Found block rdd_139_1 locally\n",
      "16/04/28 19:56:56 INFO CacheManager: Partition rdd_151_0 not found, computing it\n",
      "16/04/28 19:56:56 INFO BlockManager: Found block rdd_139_0 locally\n",
      "16/04/28 19:56:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "16/04/28 19:56:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "16/04/28 19:56:56 INFO MemoryStore: Block rdd_151_0 stored as values in memory (estimated size 2.6 KB, free 592.0 KB)\n",
      "16/04/28 19:56:56 INFO MemoryStore: Block rdd_151_1 stored as values in memory (estimated size 2.6 KB, free 594.6 KB)\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Added rdd_151_0 in memory on localhost:40918 (size: 2.6 KB, free: 517.2 MB)\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Added rdd_151_1 in memory on localhost:40918 (size: 2.6 KB, free: 517.2 MB)\n",
      "16/04/28 19:56:56 INFO Executor: Finished task 0.0 in stage 180.0 (TID 68). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:56 INFO Executor: Finished task 1.0 in stage 180.0 (TID 69). 2840 bytes result sent to driver\n",
      "16/04/28 19:56:56 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 68) in 45 ms on localhost (1/2)\n",
      "16/04/28 19:56:56 INFO TaskSetManager: Finished task 1.0 in stage 180.0 (TID 69) in 45 ms on localhost (2/2)\n",
      "16/04/28 19:56:56 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:56 INFO DAGScheduler: ResultStage 180 (foreachPartition at PageRank.scala:150) finished in 0.034 s\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Job 10 finished: foreachPartition at PageRank.scala:150, took 0.404577 s\n",
      "16/04/28 19:56:56 INFO PageRank: PageRank finished iteration 9.\n",
      "16/04/28 19:56:56 INFO ZippedPartitionsRDD2: Removing RDD 133 from persistence list\n",
      "16/04/28 19:56:56 INFO BlockManager: Removing RDD 133\n",
      "16/04/28 19:56:56 INFO ZippedPartitionsRDD2: Removing RDD 139 from persistence list\n",
      "16/04/28 19:56:56 INFO BlockManager: Removing RDD 139\n",
      "16/04/28 19:56:56 INFO SparkContext: Starting job: sortBy at pagerank.scala:13\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 152 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 152 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 20 is 155 bytes\n",
      "16/04/28 19:56:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 155 bytes\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Got job 11 (sortBy at pagerank.scala:13) with 2 output partitions\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Final stage: ResultStage 206 (sortBy at pagerank.scala:13)\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 197, ShuffleMapStage 201, ShuffleMapStage 205, ShuffleMapStage 187, ShuffleMapStage 184, ShuffleMapStage 191, ShuffleMapStage 203, ShuffleMapStage 195, ShuffleMapStage 189, ShuffleMapStage 199, ShuffleMapStage 193, ShuffleMapStage 185)\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Missing parents: List()\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Submitting ResultStage 206 (MapPartitionsRDD[155] at sortBy at pagerank.scala:13), which has no missing parents\n",
      "16/04/28 19:56:56 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 11.5 KB, free 597.4 KB)\n",
      "16/04/28 19:56:56 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 4.4 KB, free 601.7 KB)\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:40918 (size: 4.4 KB, free: 517.2 MB)\n",
      "16/04/28 19:56:56 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 206 (MapPartitionsRDD[155] at sortBy at pagerank.scala:13)\n",
      "16/04/28 19:56:56 INFO TaskSchedulerImpl: Adding task set 206.0 with 2 tasks\n",
      "16/04/28 19:56:56 INFO TaskSetManager: Starting task 0.0 in stage 206.0 (TID 70, localhost, partition 0,PROCESS_LOCAL, 2898 bytes)\n",
      "16/04/28 19:56:56 INFO TaskSetManager: Starting task 1.0 in stage 206.0 (TID 71, localhost, partition 1,PROCESS_LOCAL, 2898 bytes)\n",
      "16/04/28 19:56:56 INFO Executor: Running task 0.0 in stage 206.0 (TID 70)\n",
      "16/04/28 19:56:56 INFO Executor: Running task 1.0 in stage 206.0 (TID 71)\n",
      "16/04/28 19:56:56 INFO BlockManager: Found block rdd_145_1 locally\n",
      "16/04/28 19:56:56 INFO BlockManager: Found block rdd_145_0 locally\n",
      "16/04/28 19:56:56 INFO Executor: Finished task 0.0 in stage 206.0 (TID 70). 2309 bytes result sent to driver\n",
      "16/04/28 19:56:56 INFO TaskSetManager: Finished task 0.0 in stage 206.0 (TID 70) in 63 ms on localhost (1/2)\n",
      "16/04/28 19:56:56 INFO Executor: Finished task 1.0 in stage 206.0 (TID 71). 2317 bytes result sent to driver\n",
      "16/04/28 19:56:56 INFO TaskSetManager: Finished task 1.0 in stage 206.0 (TID 71) in 66 ms on localhost (2/2)\n",
      "16/04/28 19:56:56 INFO TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:56 INFO DAGScheduler: ResultStage 206 (sortBy at pagerank.scala:13) finished in 0.045 s\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Job 11 finished: sortBy at pagerank.scala:13, took 0.212042 s\n",
      "16/04/28 19:56:56 INFO SparkContext: Starting job: take at pagerank.scala:13\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:40918 in memory (size: 4.4 KB, free: 517.2 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 2\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:40918 in memory (size: 2.3 KB, free: 517.2 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 3\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:40918 in memory (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 4\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:40918 in memory (size: 2.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 5\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:40918 in memory (size: 3.0 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 6\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:40918 in memory (size: 3.4 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 7\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:40918 in memory (size: 3.2 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 8\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:40918 in memory (size: 3.5 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 9\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:40918 in memory (size: 3.5 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 10\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:40918 in memory (size: 3.4 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 11\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:40918 in memory (size: 3.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:40918 in memory (size: 3.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:40918 in memory (size: 3.5 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:40918 in memory (size: 3.7 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 15\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:40918 in memory (size: 3.7 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 16\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:40918 in memory (size: 3.6 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 17\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:40918 in memory (size: 3.8 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:40918 in memory (size: 3.7 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 19\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:40918 in memory (size: 3.7 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 20\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:40918 in memory (size: 3.9 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 21\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:40918 in memory (size: 3.8 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Registering RDD 153 (sortBy at pagerank.scala:13)\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Got job 12 (take at pagerank.scala:13) with 1 output partitions\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Final stage: ResultStage 233 (take at pagerank.scala:13)\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 232)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 22\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 232)\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:40918 in memory (size: 3.7 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 23\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:40918 in memory (size: 3.9 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO DAGScheduler: Submitting ShuffleMapStage 232 (MapPartitionsRDD[153] at sortBy at pagerank.scala:13), which has no missing parents\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 24\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:40918 in memory (size: 3.9 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 11.4 KB, free 363.4 KB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 25\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:40918 in memory (size: 3.8 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 26\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:40918 in memory (size: 4.0 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 27\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:40918 in memory (size: 4.0 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 28\n",
      "16/04/28 19:56:56 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 4.4 KB, free 321.6 KB)\n",
      "16/04/28 19:56:56 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:40918 in memory (size: 4.0 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:56 INFO ContextCleaner: Cleaned accumulator 29\n",
      "16/04/28 19:56:57 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:40918 in memory (size: 4.1 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:57 INFO ContextCleaner: Cleaned accumulator 30\n",
      "16/04/28 19:56:57 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:40918 (size: 4.4 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:57 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 232 (MapPartitionsRDD[153] at sortBy at pagerank.scala:13)\n",
      "16/04/28 19:56:57 INFO TaskSchedulerImpl: Adding task set 232.0 with 2 tasks\n",
      "16/04/28 19:56:57 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:40918 in memory (size: 4.0 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:57 INFO ContextCleaner: Cleaned accumulator 31\n",
      "16/04/28 19:56:57 INFO TaskSetManager: Starting task 0.0 in stage 232.0 (TID 72, localhost, partition 0,PROCESS_LOCAL, 2887 bytes)\n",
      "16/04/28 19:56:57 INFO TaskSetManager: Starting task 1.0 in stage 232.0 (TID 73, localhost, partition 1,PROCESS_LOCAL, 2887 bytes)\n",
      "16/04/28 19:56:57 INFO Executor: Running task 0.0 in stage 232.0 (TID 72)\n",
      "16/04/28 19:56:57 INFO BlockManager: Found block rdd_145_0 locally\n",
      "16/04/28 19:56:57 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:40918 in memory (size: 4.0 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:57 INFO Executor: Running task 1.0 in stage 232.0 (TID 73)\n",
      "16/04/28 19:56:57 INFO BlockManager: Found block rdd_145_1 locally\n",
      "16/04/28 19:56:57 INFO ContextCleaner: Cleaned accumulator 32\n",
      "16/04/28 19:56:57 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:40918 in memory (size: 4.2 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:57 INFO Executor: Finished task 0.0 in stage 232.0 (TID 72). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:57 INFO TaskSetManager: Finished task 0.0 in stage 232.0 (TID 72) in 77 ms on localhost (1/2)\n",
      "16/04/28 19:56:57 INFO Executor: Finished task 1.0 in stage 232.0 (TID 73). 2254 bytes result sent to driver\n",
      "16/04/28 19:56:57 INFO ContextCleaner: Cleaned shuffle 22\n",
      "16/04/28 19:56:57 INFO TaskSetManager: Finished task 1.0 in stage 232.0 (TID 73) in 86 ms on localhost (2/2)\n",
      "16/04/28 19:56:57 INFO TaskSchedulerImpl: Removed TaskSet 232.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:57 INFO DAGScheduler: ShuffleMapStage 232 (sortBy at pagerank.scala:13) finished in 0.109 s\n",
      "16/04/28 19:56:57 INFO DAGScheduler: looking for newly runnable stages\n",
      "16/04/28 19:56:57 INFO DAGScheduler: running: Set()\n",
      "16/04/28 19:56:57 INFO DAGScheduler: waiting: Set(ResultStage 233)\n",
      "16/04/28 19:56:57 INFO DAGScheduler: failed: Set()\n",
      "16/04/28 19:56:57 INFO DAGScheduler: Submitting ResultStage 233 (MapPartitionsRDD[157] at sortBy at pagerank.scala:13), which has no missing parents\n",
      "16/04/28 19:56:57 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 3.4 KB, free 258.1 KB)\n",
      "16/04/28 19:56:57 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 1991.0 B, free 260.0 KB)\n",
      "16/04/28 19:56:57 INFO BlockManager: Removing RDD 151\n",
      "16/04/28 19:56:57 INFO ContextCleaner: Cleaned RDD 151\n",
      "16/04/28 19:56:57 INFO ContextCleaner: Cleaned accumulator 33\n",
      "16/04/28 19:56:57 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:40918 (size: 1991.0 B, free: 517.4 MB)\n",
      "16/04/28 19:56:57 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 233 (MapPartitionsRDD[157] at sortBy at pagerank.scala:13)\n",
      "16/04/28 19:56:57 INFO TaskSchedulerImpl: Adding task set 233.0 with 1 tasks\n",
      "16/04/28 19:56:57 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:40918 in memory (size: 4.1 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:57 INFO ContextCleaner: Cleaned accumulator 34\n",
      "16/04/28 19:56:57 INFO TaskSetManager: Starting task 0.0 in stage 233.0 (TID 74, localhost, partition 0,NODE_LOCAL, 1953 bytes)\n",
      "16/04/28 19:56:57 INFO Executor: Running task 0.0 in stage 233.0 (TID 74)\n",
      "16/04/28 19:56:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "16/04/28 19:56:57 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:40918 in memory (size: 4.1 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:57 INFO ContextCleaner: Cleaned accumulator 35\n",
      "16/04/28 19:56:57 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:40918 in memory (size: 4.2 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:57 INFO ContextCleaner: Cleaned accumulator 36\n",
      "16/04/28 19:56:57 INFO Executor: Finished task 0.0 in stage 233.0 (TID 74). 1496 bytes result sent to driver\n",
      "16/04/28 19:56:57 INFO TaskSetManager: Finished task 0.0 in stage 233.0 (TID 74) in 176 ms on localhost (1/1)\n",
      "16/04/28 19:56:57 INFO TaskSchedulerImpl: Removed TaskSet 233.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:57 INFO DAGScheduler: ResultStage 233 (take at pagerank.scala:13) finished in 0.187 s\n",
      "16/04/28 19:56:57 INFO DAGScheduler: Job 12 finished: take at pagerank.scala:13, took 0.652422 s\n",
      "16/04/28 19:56:57 INFO SparkContext: Starting job: take at pagerank.scala:13\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 152 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 152 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 20 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 155 bytes\n",
      "16/04/28 19:56:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 155 bytes\n",
      "16/04/28 19:56:57 INFO DAGScheduler: Got job 13 (take at pagerank.scala:13) with 1 output partitions\n",
      "16/04/28 19:56:57 INFO DAGScheduler: Final stage: ResultStage 260 (take at pagerank.scala:13)\n",
      "16/04/28 19:56:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 259)\n",
      "16/04/28 19:56:57 INFO DAGScheduler: Missing parents: List()\n",
      "16/04/28 19:56:57 INFO DAGScheduler: Submitting ResultStage 260 (MapPartitionsRDD[157] at sortBy at pagerank.scala:13), which has no missing parents\n",
      "16/04/28 19:56:57 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 3.4 KB, free 216.6 KB)\n",
      "16/04/28 19:56:57 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 1991.0 B, free 218.6 KB)\n",
      "16/04/28 19:56:57 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:40918 (size: 1991.0 B, free: 517.4 MB)\n",
      "16/04/28 19:56:57 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 260 (MapPartitionsRDD[157] at sortBy at pagerank.scala:13)\n",
      "16/04/28 19:56:57 INFO TaskSchedulerImpl: Adding task set 260.0 with 1 tasks\n",
      "16/04/28 19:56:57 INFO TaskSetManager: Starting task 0.0 in stage 260.0 (TID 75, localhost, partition 1,NODE_LOCAL, 1953 bytes)\n",
      "16/04/28 19:56:57 INFO Executor: Running task 0.0 in stage 260.0 (TID 75)\n",
      "16/04/28 19:56:57 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks\n",
      "16/04/28 19:56:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "16/04/28 19:56:57 INFO Executor: Finished task 0.0 in stage 260.0 (TID 75). 1530 bytes result sent to driver\n",
      "16/04/28 19:56:57 INFO TaskSetManager: Finished task 0.0 in stage 260.0 (TID 75) in 23 ms on localhost (1/1)\n",
      "16/04/28 19:56:57 INFO TaskSchedulerImpl: Removed TaskSet 260.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:57 INFO DAGScheduler: ResultStage 260 (take at pagerank.scala:13) finished in 0.018 s\n",
      "16/04/28 19:56:57 INFO DAGScheduler: Job 13 finished: take at pagerank.scala:13, took 0.265472 s\n",
      "16/04/28 19:56:58 INFO SparkContext: Starting job: saveAsTextFile at pagerank.scala:14\n",
      "16/04/28 19:56:58 INFO DAGScheduler: Got job 14 (saveAsTextFile at pagerank.scala:14) with 4 output partitions\n",
      "16/04/28 19:56:58 INFO DAGScheduler: Final stage: ResultStage 261 (saveAsTextFile at pagerank.scala:14)\n",
      "16/04/28 19:56:58 INFO DAGScheduler: Parents of final stage: List()\n",
      "16/04/28 19:56:58 INFO DAGScheduler: Missing parents: List()\n",
      "16/04/28 19:56:58 INFO DAGScheduler: Submitting ResultStage 261 (MapPartitionsRDD[159] at saveAsTextFile at pagerank.scala:14), which has no missing parents\n",
      "16/04/28 19:56:58 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 63.4 KB, free 282.0 KB)\n",
      "16/04/28 19:56:58 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 21.4 KB, free 303.4 KB)\n",
      "16/04/28 19:56:58 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:40918 (size: 21.4 KB, free: 517.3 MB)\n",
      "16/04/28 19:56:58 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006\n",
      "16/04/28 19:56:58 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 261 (MapPartitionsRDD[159] at saveAsTextFile at pagerank.scala:14)\n",
      "16/04/28 19:56:58 INFO TaskSchedulerImpl: Adding task set 261.0 with 4 tasks\n",
      "16/04/28 19:56:58 INFO TaskSetManager: Starting task 0.0 in stage 261.0 (TID 76, localhost, partition 0,PROCESS_LOCAL, 2285 bytes)\n",
      "16/04/28 19:56:58 INFO TaskSetManager: Starting task 1.0 in stage 261.0 (TID 77, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)\n",
      "16/04/28 19:56:58 INFO TaskSetManager: Starting task 2.0 in stage 261.0 (TID 78, localhost, partition 2,PROCESS_LOCAL, 2319 bytes)\n",
      "16/04/28 19:56:58 INFO TaskSetManager: Starting task 3.0 in stage 261.0 (TID 79, localhost, partition 3,PROCESS_LOCAL, 2319 bytes)\n",
      "16/04/28 19:56:58 INFO Executor: Running task 0.0 in stage 261.0 (TID 76)\n",
      "16/04/28 19:56:58 INFO Executor: Running task 1.0 in stage 261.0 (TID 77)\n",
      "16/04/28 19:56:58 INFO Executor: Running task 2.0 in stage 261.0 (TID 78)\n",
      "16/04/28 19:56:58 INFO Executor: Running task 3.0 in stage 261.0 (TID 79)\n",
      "16/04/28 19:56:58 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:40918 in memory (size: 1991.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:58 INFO ContextCleaner: Cleaned accumulator 39\n",
      "16/04/28 19:56:58 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:40918 in memory (size: 1991.0 B, free: 517.3 MB)\n",
      "16/04/28 19:56:58 INFO ContextCleaner: Cleaned accumulator 38\n",
      "16/04/28 19:56:58 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:40918 in memory (size: 4.4 KB, free: 517.4 MB)\n",
      "16/04/28 19:56:58 INFO ContextCleaner: Cleaned accumulator 37\n",
      "16/04/28 19:56:58 INFO ContextCleaner: Cleaned shuffle 24\n",
      "16/04/28 19:56:58 INFO ContextCleaner: Cleaned accumulator 18\n",
      "16/04/28 19:56:58 INFO ContextCleaner: Cleaned accumulator 14\n",
      "16/04/28 19:56:58 INFO ContextCleaner: Cleaned accumulator 13\n",
      "16/04/28 19:56:58 INFO ContextCleaner: Cleaned accumulator 12\n",
      "16/04/28 19:56:58 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:40918 in memory (size: 1967.0 B, free: 517.4 MB)\n",
      "16/04/28 19:56:58 INFO ContextCleaner: Cleaned accumulator 1\n",
      "16/04/28 19:56:59 INFO FileOutputCommitter: Saved output of task 'attempt_201604281956_0261_m_000002_78' to file:/home/hdanish/Documents/UCB/W261/Week13/pr10g-1/_temporary/0/task_201604281956_0261_m_000002\n",
      "16/04/28 19:56:59 INFO SparkHadoopMapRedUtil: attempt_201604281956_0261_m_000002_78: Committed\n",
      "16/04/28 19:56:59 INFO FileOutputCommitter: Saved output of task 'attempt_201604281956_0261_m_000001_77' to file:/home/hdanish/Documents/UCB/W261/Week13/pr10g-1/_temporary/0/task_201604281956_0261_m_000001\n",
      "16/04/28 19:56:59 INFO FileOutputCommitter: Saved output of task 'attempt_201604281956_0261_m_000003_79' to file:/home/hdanish/Documents/UCB/W261/Week13/pr10g-1/_temporary/0/task_201604281956_0261_m_000003\n",
      "16/04/28 19:56:59 INFO SparkHadoopMapRedUtil: attempt_201604281956_0261_m_000003_79: Committed\n",
      "16/04/28 19:56:59 INFO FileOutputCommitter: Saved output of task 'attempt_201604281956_0261_m_000000_76' to file:/home/hdanish/Documents/UCB/W261/Week13/pr10g-1/_temporary/0/task_201604281956_0261_m_000000\n",
      "16/04/28 19:56:59 INFO SparkHadoopMapRedUtil: attempt_201604281956_0261_m_000000_76: Committed\n",
      "16/04/28 19:56:59 INFO SparkHadoopMapRedUtil: attempt_201604281956_0261_m_000001_77: Committed\n",
      "16/04/28 19:56:59 INFO Executor: Finished task 2.0 in stage 261.0 (TID 78). 1864 bytes result sent to driver\n",
      "16/04/28 19:56:59 INFO Executor: Finished task 3.0 in stage 261.0 (TID 79). 1864 bytes result sent to driver\n",
      "16/04/28 19:56:59 INFO Executor: Finished task 1.0 in stage 261.0 (TID 77). 1864 bytes result sent to driver\n",
      "16/04/28 19:56:59 INFO TaskSetManager: Finished task 3.0 in stage 261.0 (TID 79) in 852 ms on localhost (1/4)\n",
      "16/04/28 19:56:59 INFO TaskSetManager: Finished task 1.0 in stage 261.0 (TID 77) in 864 ms on localhost (2/4)\n",
      "16/04/28 19:56:59 INFO Executor: Finished task 0.0 in stage 261.0 (TID 76). 1864 bytes result sent to driver\n",
      "16/04/28 19:56:59 INFO TaskSetManager: Finished task 0.0 in stage 261.0 (TID 76) in 1170 ms on localhost (3/4)\n",
      "16/04/28 19:56:59 INFO TaskSetManager: Finished task 2.0 in stage 261.0 (TID 78) in 874 ms on localhost (4/4)\n",
      "16/04/28 19:56:59 INFO DAGScheduler: ResultStage 261 (saveAsTextFile at pagerank.scala:14) finished in 1.173 s\n",
      "16/04/28 19:56:59 INFO DAGScheduler: Job 14 finished: saveAsTextFile at pagerank.scala:14, took 1.465321 s\n",
      "16/04/28 19:56:59 INFO TaskSchedulerImpl: Removed TaskSet 261.0, whose tasks have all completed, from pool \n",
      "16/04/28 19:56:59 INFO SparkContext: Invoking stop() from shutdown hook\n",
      "16/04/28 19:56:59 INFO SparkUI: Stopped Spark web UI at http://10.0.2.15:4041\n",
      "16/04/28 19:56:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "16/04/28 19:57:00 INFO MemoryStore: MemoryStore cleared\n",
      "16/04/28 19:57:00 INFO BlockManager: BlockManager stopped\n",
      "16/04/28 19:57:00 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "16/04/28 19:57:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "16/04/28 19:57:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.\n",
      "16/04/28 19:57:00 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.\n",
      "16/04/28 19:57:00 INFO SparkContext: Successfully stopped SparkContext\n",
      "16/04/28 19:57:00 INFO ShutdownHookManager: Shutdown hook called\n",
      "16/04/28 19:57:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-1a966d7a-0651-418c-b009-0762aa5e49d2\n",
      "16/04/28 19:57:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-1a966d7a-0651-418c-b009-0762aa5e49d2/httpd-9cb04eaa-6892-4f76-afd2-e25c04a55a54\n"
     ]
    }
   ],
   "source": [
    "!/home/hdanish/Downloads/spark-1.6.1-bin-hadoop2.6//bin/spark-submit --class \"HWPageRank\" --master local[4] \\\n",
    " target/scala-2.10/pagerank_2.10-1.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,2.837824310201201)\r\n",
      "(3,2.4868526601543555)\r\n",
      "(5,0.7503400819355781)\r\n",
      "(4,0.3625952805244703)\r\n",
      "(6,0.3625952805244703)\r\n",
      "(1,0.3040900819355781)\r\n",
      "(8,0.15)\r\n",
      "(10,0.15)\r\n",
      "(11,0.15)\r\n",
      "(7,0.15)\r\n",
      "(9,0.15)\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./pr10g-1/part-* > ./pr10g-1.txt\n",
    "!cat ./pr10g-1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
